{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10356362,"sourceType":"datasetVersion","datasetId":6413607}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-03T17:34:47.616044Z","iopub.execute_input":"2025-01-03T17:34:47.616384Z","iopub.status.idle":"2025-01-03T17:34:47.626747Z","shell.execute_reply.started":"2025-01-03T17:34:47.616354Z","shell.execute_reply":"2025-01-03T17:34:47.625892Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/model-dataset-new-1/2015.csv\n/kaggle/input/model-dataset-new-1/2017.csv\n/kaggle/input/model-dataset-new-1/2019.csv\n/kaggle/input/model-dataset-new-1/main_data.csv\n/kaggle/input/model-dataset-new-1/2018.csv\n/kaggle/input/model-dataset-new-1/2016.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport logging\nfrom sklearn.preprocessing import StandardScaler\nfrom transformers import BartTokenizer, BartForConditionalGeneration\nimport logging\nimport re\nimport spacy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport random\nfrom moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\nimport os\nimport time\nimport torch\n\n# Setting up logging\nlogging.basicConfig(level=logging.INFO)\n\n# Load spaCy model for NER\nnlp = spacy.load(\"en_core_web_sm\")\n\nimport pandas as pd\nimport logging\nfrom sklearn.preprocessing import StandardScaler\n\nimport pandas as pd\nimport logging\nfrom sklearn.preprocessing import StandardScaler\n\nimport pandas as pd\nimport logging\nfrom sklearn.preprocessing import StandardScaler\n\ndef load_and_preprocess_data(file_path):\n    try:\n        logging.info(f\"Loading data from {file_path}\")\n        # Load data\n        if file_path.endswith('.csv'):\n            data = pd.read_csv(file_path)\n        elif file_path.endswith('.xlsx'):\n            data = pd.read_excel(file_path)\n        elif file_path.endswith('.txt'):\n            data = pd.read_csv(file_path, delimiter='\\t')\n        else:\n            raise ValueError(\"Unsupported file format.\")\n        \n        logging.info(\"Data loaded successfully\")\n        \n        # Detect and convert data types\n        for col in data.columns:\n            try:\n                data[col] = pd.to_numeric(data[col], errors='coerce')\n            except ValueError:\n                pass\n        \n        # Handle missing values\n        data.fillna(data.mean(), inplace=True)\n        \n        # Handle categorical data\n        categorical_cols = data.select_dtypes(include=['object']).columns\n        data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n        \n        # Normalize numeric data\n        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n        scaler = StandardScaler()\n        data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n        \n        logging.info(\"Data preprocessing completed\")\n        return data\n    except Exception as e:\n        logging.error(f\"Error loading and preprocessing data: {e}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:42:43.079118Z","iopub.execute_input":"2025-01-03T12:42:43.079544Z","iopub.status.idle":"2025-01-03T12:42:52.619813Z","shell.execute_reply.started":"2025-01-03T12:42:43.079515Z","shell.execute_reply":"2025-01-03T12:42:52.619128Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def perform_eda(data):\n    try:\n        eda_summary = {\n            \"shape\": data.shape,\n            \"columns\": data.columns.tolist(),\n            \"dtypes\": data.dtypes.tolist(),\n            \"null_counts\": data.isnull().sum().tolist(),\n            \"describe\": data.describe().to_dict()\n        }\n        return eda_summary\n    except Exception as e:\n        logging.error(f\"Error performing EDA: {e}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:42:52.621537Z","iopub.execute_input":"2025-01-03T12:42:52.621987Z","iopub.status.idle":"2025-01-03T12:42:52.626282Z","shell.execute_reply.started":"2025-01-03T12:42:52.621964Z","shell.execute_reply":"2025-01-03T12:42:52.625531Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from transformers import BartTokenizer, BartForConditionalGeneration\nimport spacy\nimport re\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef analyze_prompt_for_insights(prompt, model_name=\"facebook/bart-large\"):\n    try:\n        logging.info(\"Analyzing prompt for insights\")\n        tokenizer = BartTokenizer.from_pretrained(model_name)\n        model = BartForConditionalGeneration.from_pretrained(model_name)\n        \n        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n        input_ids = inputs.input_ids\n        attention_mask = inputs.attention_mask\n        \n        outputs = model.generate(\n            input_ids,\n            attention_mask=attention_mask,\n            max_length=200,\n            num_return_sequences=1,\n            temperature=0.7,\n            top_p=0.9,\n            top_k=50,\n            no_repeat_ngram_size=2,\n            pad_token_id=tokenizer.eos_token_id\n        )\n        \n        generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n        insights = extract_insights_from_text(generated_text)\n        \n        insights_list = [key for key, value in insights.items() if value]\n        if not insights_list:\n            raise ValueError(\"No insights could be extracted from the provided prompt.\")\n        \n        logging.info(f\"Insights extracted: {insights_list}\")\n        return insights_list\n    except Exception as e:\n        logging.error(f\"Error in analyzing prompt for insights: {e}\")\n        return []\n\ndef extract_insights_from_text(text):\n    possible_insights = [\"trend\", \"comparison\", \"distribution\", \"correlation\", \"pattern\", \"anomaly\", \"outlier\", \"relationship\", \"performance\", \"growth\"]\n    insights = {insight: False for insight in possible_insights}\n    text = text.lower()\n    \n    for insight in possible_insights:\n        if re.search(r'\\b' + re.escape(insight) + r'\\b', text):\n            insights[insight] = True\n    \n    doc = nlp(text)\n    entities = [(ent.text, ent.label_) for ent in doc.ents]\n    insights['entities'] = entities\n    \n    return insights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:42:52.627424Z","iopub.execute_input":"2025-01-03T12:42:52.627723Z","iopub.status.idle":"2025-01-03T12:42:53.229152Z","shell.execute_reply.started":"2025-01-03T12:42:52.627692Z","shell.execute_reply":"2025-01-03T12:42:53.228530Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import plotly.express as px\nimport pandas as pd\nimport logging\n\ndef generate_visualizations(data, insights):\n    try:\n        logging.info(\"Generating visualizations\")\n        if data.empty:\n            raise ValueError(\"Data is empty.\")\n        if not insights:\n            raise ValueError(\"No insights available to generate visualizations.\")\n        \n        visuals = []\n        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n        categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n        \n        if 'Date' in data.columns or 'Datetime' in data.columns:\n            time_column = 'Date' if 'Date' in data.columns else 'Datetime'\n            if numeric_columns.any():\n                fig = px.line(data, x=time_column, y=numeric_columns, title=f\"Time Series Plot for {', '.join(numeric_columns)}\")\n                visuals.append(fig)\n        \n        if len(numeric_columns) > 1:\n            corr_matrix = data[numeric_columns].corr()\n            fig = px.imshow(corr_matrix, text_auto=True, title='Correlation Matrix')\n            visuals.append(fig)\n        \n        for col in categorical_columns:\n            fig = px.histogram(data, x=col, title=f\"Distribution of {col}\")\n            visuals.append(fig)\n        \n        if len(numeric_columns) > 1:\n            fig = px.scatter_matrix(data, dimensions=numeric_columns, title='Pairwise Relationships')\n            visuals.append(fig)\n        \n        if not visuals:\n            return None\n        \n        logging.info(f\"Generated {len(visuals)} visualizations\")\n        return visuals\n    except Exception as e:\n        logging.error(f\"Error generating visualizations: {e}\")\n        raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# data = pd.read_csv(file_path)\n# insights = \"Sample insights based on the data\"\n# visuals = generate_visualizations(data, insights)\n\n# # To display the visualizations in a Jupyter notebook\n# for fig in visuals:\n#     fig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:31:41.348819Z","iopub.execute_input":"2025-01-03T13:31:41.349111Z","iopub.status.idle":"2025-01-03T13:31:41.356561Z","shell.execute_reply.started":"2025-01-03T13:31:41.349089Z","shell.execute_reply":"2025-01-03T13:31:41.355743Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport logging\n\ndef generate_default_frames(data):\n    logging.info(\"Generating default frames from data\")\n    frames = []\n    \n    # Generate a basic time series plot if a date column is present\n    date_column = None\n    for col in data.columns:\n        if 'date' in col.lower() or 'time' in col.lower():\n            date_column = col\n            break\n    \n    if date_column:\n        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n        if len(numeric_columns) > 0:\n            plt.figure(figsize=(10, 6))\n            for col in numeric_columns:\n                plt.plot(data[date_column], data[col], label=col)\n            plt.title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n            plt.xlabel('Time')\n            plt.ylabel('Values')\n            plt.xticks(rotation=45)\n            plt.legend()\n            frames.append(plt)\n    \n    # Generate a correlation matrix plot\n    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n        corr_matrix = data.corr()\n        plt.figure(figsize=(10, 6))\n        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n        plt.title('Correlation Matrix')\n        frames.append(plt)\n    \n    # Generate distribution plots for numeric columns\n    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n    for col in numeric_columns:\n        plt.figure(figsize=(8, 6))\n        sns.histplot(data[col], bins=10, kde=True)\n        plt.title(f\"Distribution of {col}\")\n        frames.append(plt)\n    \n    logging.info(f\"Generated {len(frames)} default frames\")\n    return frames","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:32:13.903541Z","iopub.execute_input":"2025-01-03T13:32:13.903821Z","iopub.status.idle":"2025-01-03T13:32:13.911435Z","shell.execute_reply.started":"2025-01-03T13:32:13.903800Z","shell.execute_reply":"2025-01-03T13:32:13.910585Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# print(frames)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:32:14.492944Z","iopub.execute_input":"2025-01-03T13:32:14.493227Z","iopub.status.idle":"2025-01-03T13:32:14.497203Z","shell.execute_reply.started":"2025-01-03T13:32:14.493207Z","shell.execute_reply":"2025-01-03T13:32:14.496317Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n\ndef create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n    if not frames:\n        raise ValueError(\"No frames to create video from.\")\n    \n    video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n    video = video_clips[0]\n    for clip in video_clips[1:]:\n        video = concatenate_videoclips([video, clip], method=\"compose\")\n    \n    if audio_file and os.path.isfile(audio_file):\n        audio = AudioFileClip(audio_file)\n        video = video.set_audio(audio)\n    \n    video.write_videofile(video_file, codec=\"libx264\", fps=24)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:32:14.742985Z","iopub.execute_input":"2025-01-03T13:32:14.743322Z","iopub.status.idle":"2025-01-03T13:32:14.748882Z","shell.execute_reply.started":"2025-01-03T13:32:14.743296Z","shell.execute_reply":"2025-01-03T13:32:14.748000Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n    frames = generate_default_frames(data)\n    if not frames:\n        raise ValueError(\"No frames generated from data.\")\n    \n    if os.path.exists(title_image):\n        title_image_clip = Image.open(title_image)\n        frames.insert(0, title_image_clip)\n    \n    create_video_from_frames(frames, audio_file)\n    print(\"Video successfully generated!\")\n\ndef data_storytelling_pipeline(file_path, prompt, audio_file=None):\n    try:\n        start_time = time.time()\n        \n        logging.info(\"Loading and preprocessing data...\")\n        data = load_and_preprocess_data(file_path)\n        logging.debug(f\"Loaded Data: {data.head()}\")\n        \n        logging.info(\"Performing EDA...\")\n        eda_summary = perform_eda(data)\n        logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n        logging.info(\"Analyzing the user's prompt...\")\n        insights = analyze_prompt_for_insights(prompt)\n        logging.debug(f\"Extracted insights: {insights}\")\n        \n        logging.info(\"Creating the infographic video...\")\n        generate_infographic_video(data, insights, audio_file=audio_file)\n        \n        end_time = time.time()\n        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n    except FileNotFoundError as fnf_error:\n        logging.error(f\"File not found: {fnf_error}\")\n        raise\n    except pd.errors.ParserError as parser_error:\n        logging.error(f\"Error parsing the file: {parser_error}\")\n        raise\n    except TypeError as type_error:\n        logging.error(f\"Type error: {type_error}\")\n        raise\n    except ValueError as value_error:\n        logging.error(f\"Value error: {value_error}\")\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {e}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:42:53.289044Z","iopub.execute_input":"2025-01-03T12:42:53.289339Z","iopub.status.idle":"2025-01-03T12:42:53.305369Z","shell.execute_reply.started":"2025-01-03T12:42:53.289313Z","shell.execute_reply":"2025-01-03T12:42:53.304697Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\n# # # Predefined prompts for prompt engineering\n# # predefined_prompts = [\n# #     \"Analyze the sales trends over time and regional performance.\",\n# #     \"Identify key trends, comparisons, distributions, and correlations in the data.\",\n# #     \"Generate insights on the performance and growth of different regions.\",\n# #     \"Highlight any anomalies or outliers in the sales data.\",\n# #     \"Compare the sales performance across different product categories.\",\n# #     \"Analyze the correlation between sales and marketing spend.\",\n# #     \"Identify patterns in customer purchase behavior.\",\n# #     \"Generate insights on the distribution of sales across different regions.\",\n# #     \"Analyze the relationship between sales and customer demographics.\",\n# #     \"Identify key performance indicators for the sales team.\",\n# #     # Add more prompts as needed\n# # ]\n\n# # # Test the pipeline with predefined prompts\n# # for test_prompt in predefined_prompts:\n# #     try:\n# #         logging.info(f\"Testing with prompt: {test_prompt}\")\n# #         data_storytelling_pipeline(file_path, test_prompt, audio_file=audio_file)\n# #     except Exception as e:\n# #         logging.error(f\"Error with prompt '{test_prompt}': {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:42:53.306048Z","iopub.execute_input":"2025-01-03T12:42:53.306235Z","iopub.status.idle":"2025-01-03T12:42:53.322383Z","shell.execute_reply.started":"2025-01-03T12:42:53.306219Z","shell.execute_reply":"2025-01-03T12:42:53.321636Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n# import numpy as np\n\n# def generate_default_frames(data):\n#     logging.info(\"Generating default frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             plt.figure(figsize=(10, 6))\n#             for col in numeric_columns:\n#                 plt.plot(data[date_column], data[col], label=col)\n#             plt.title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             plt.xlabel('Time')\n#             plt.ylabel('Values')\n#             plt.xticks(rotation=45)\n#             plt.legend()\n#             frames.append(plt)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         plt.figure(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n#         plt.title('Correlation Matrix')\n#         frames.append(plt)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         plt.figure(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True)\n#         plt.title(f\"Distribution of {col}\")\n#         frames.append(plt)\n    \n#     logging.info(f\"Generated {len(frames)} default frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = [ImageSequenceClip([np.array(frame.canvas.buffer_rgba())], fps=24) for frame in frames]\n    \n#     video = video_clips[0]\n#     for clip in video_clips[1:]:\n#         video = concatenate_videoclips([video, clip], method=\"compose\")\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_default_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:42:53.323142Z","iopub.execute_input":"2025-01-03T12:42:53.323406Z","iopub.status.idle":"2025-01-03T12:42:53.339760Z","shell.execute_reply.started":"2025-01-03T12:42:53.323387Z","shell.execute_reply":"2025-01-03T12:42:53.338997Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport logging\nimport os\nfrom PIL import Image\nfrom moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\nimport numpy as np\nimport io\n\ndef generate_default_frames(data):\n    logging.info(\"Generating default frames from data\")\n    frames = []\n    \n    # Generate a basic time series plot if a date column is present\n    date_column = None\n    for col in data.columns:\n        if 'date' in col.lower() or 'time' in col.lower():\n            date_column = col\n            break\n    \n    if date_column:\n        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n        if len(numeric_columns) > 0:\n            fig, ax = plt.subplots(figsize=(10, 6))\n            for col in numeric_columns:\n                ax.plot(data[date_column], data[col], label=col)\n            ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n            ax.set_xlabel('Time')\n            ax.set_ylabel('Values')\n            ax.legend()\n            buf = io.BytesIO()\n            fig.savefig(buf, format='png')\n            buf.seek(0)\n            img = Image.open(buf)\n            frames.append(img)\n            plt.close(fig)\n    \n    # Generate a correlation matrix plot\n    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n        corr_matrix = data.corr()\n        fig, ax = plt.subplots(figsize=(10, 6))\n        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n        ax.set_title('Correlation Matrix')\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(img)\n        plt.close(fig)\n    \n    # Generate distribution plots for numeric columns\n    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n    for col in numeric_columns:\n        fig, ax = plt.subplots(figsize=(8, 6))\n        sns.histplot(data[col], bins=10, kde=True, ax=ax)\n        ax.set_title(f\"Distribution of {col}\")\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(img)\n        plt.close(fig)\n    \n    logging.info(f\"Generated {len(frames)} default frames\")\n    return frames\n\ndef create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n    if not frames:\n        raise ValueError(\"No frames to create video from.\")\n    \n    logging.info(\"Creating video from frames\")\n    video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n    video = video_clips[0]\n    for clip in video_clips[1:]:\n        video = concatenate_videoclips([video, clip], method=\"compose\")\n    \n    if audio_file and os.path.isfile(audio_file):\n        audio = AudioFileClip(audio_file)\n        video = video.set_audio(audio)\n    \n    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n    logging.info(f\"Video saved as {video_file}\")\n\ndef generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n    frames = generate_default_frames(data)\n    if not frames:\n        raise ValueError(\"No frames generated from data.\")\n    \n    if os.path.exists(title_image):\n        title_image_clip = Image.open(title_image)\n        title_image_clip = title_image_clip.convert(\"RGBA\")\n        title_image_clip = np.array(title_image_clip)\n        frames.insert(0, title_image_clip)\n    \n    create_video_from_frames(frames, audio_file)\n    print(\"Video successfully generated!\")\n\ndef data_storytelling_pipeline(file_path, prompt, audio_file=None):\n    try:\n        start_time = time.time()\n        \n        logging.info(\"Loading and preprocessing data...\")\n        data = load_and_preprocess_data(file_path)\n        logging.debug(f\"Loaded Data: {data.head()}\")\n        \n        logging.info(\"Performing EDA...\")\n        eda_summary = perform_eda(data)\n        logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n        logging.info(\"Analyzing the user's prompt...\")\n        insights = analyze_prompt_for_insights(prompt)\n        logging.debug(f\"Extracted insights: {insights}\")\n        \n        logging.info(\"Creating the infographic video...\")\n        generate_infographic_video(data, insights, audio_file=audio_file)\n        \n        end_time = time.time()\n        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n    except FileNotFoundError as fnf_error:\n        logging.error(f\"File not found: {fnf_error}\")\n        raise\n    except pd.errors.ParserError as parser_error:\n        logging.error(f\"Error parsing the file: {parser_error}\")\n        raise\n    except TypeError as type_error:\n        logging.error(f\"Type error: {type_error}\")\n        raise\n    except ValueError as value_error:\n        logging.error(f\"Value error: {value_error}\")\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {e}\")\n        raise\n\n# Example usage:\nfile_path = '/kaggle/input/model-dataset-new-1/2015.csv'\nprompt = \"Analyze the country and region data\"\naudio_file = \"/kaggle/working/\"\ntitle_image = \"/kaggle/working/\"\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"Data file not found: {file_path}\")\nif not os.path.exists(audio_file):\n    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\nif not os.path.exists(title_image):\n    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\ndata_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:42:53.340818Z","iopub.execute_input":"2025-01-03T12:42:53.341096Z","iopub.status.idle":"2025-01-03T12:43:10.241528Z","shell.execute_reply.started":"2025-01-03T12:42:53.341074Z","shell.execute_reply":"2025-01-03T12:43:10.240695Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0c44840ae9242078309fef7a95b2077"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56a26da921cb4e9f95e81bb73f5b60cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2cf8964591d40d8b76c4de323dd67ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8463955afd884a519535cbf91c1b127f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4909334b0e9a4fdb8d1190e03f6575a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"386099e600d94dd9a735448b6147676b"}},"metadata":{}},{"name":"stdout","text":"Moviepy - Building video final_video.mp4.\nMoviepy - Writing video final_video.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready final_video.mp4\nVideo successfully generated!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport logging\nimport os\nfrom PIL import Image\nfrom moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\nimport numpy as np\nimport io\nfrom matplotlib.animation import FuncAnimation\n\ndef generate_animated_frames(data):\n    logging.info(\"Generating animated frames from data\")\n    frames = []\n    \n    # Generate a basic time series plot if a date column is present\n    date_column = None\n    for col in data.columns:\n        if 'date' in col.lower() or 'time' in col.lower():\n            date_column = col\n            break\n    \n    if date_column:\n        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n        if len(numeric_columns) > 0:\n            fig, ax = plt.subplots(figsize=(10, 6))\n            lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n            ax.set_xlim(data[date_column].min(), data[date_column].max())\n            ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n            ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n            ax.set_xlabel('Time')\n            ax.set_ylabel('Values')\n            ax.legend()\n\n            def update(frame):\n                for line, col in zip(lines, numeric_columns):\n                    line.set_data(data[date_column][:frame], data[col][:frame])\n                return lines\n\n            ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n            for i in range(len(data)):\n                update(i)\n                buf = io.BytesIO()\n                fig.savefig(buf, format='png')\n                buf.seek(0)\n                img = Image.open(buf)\n                frames.append(img)\n            plt.close(fig)\n    \n    # Generate a correlation matrix plot\n    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n        corr_matrix = data.corr()\n        fig, ax = plt.subplots(figsize=(10, 6))\n        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n        ax.set_title('Correlation Matrix')\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(img)\n        plt.close(fig)\n    \n    # Generate distribution plots for numeric columns\n    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n    for col in numeric_columns:\n        fig, ax = plt.subplots(figsize=(8, 6))\n        sns.histplot(data[col], bins=10, kde=True, ax=ax)\n        ax.set_title(f\"Distribution of {col}\")\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(img)\n        plt.close(fig)\n    \n    logging.info(f\"Generated {len(frames)} animated frames\")\n    return frames\n\ndef create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n    if not frames:\n        raise ValueError(\"No frames to create video from.\")\n    \n    logging.info(\"Creating video from frames\")\n    video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n    video = video_clips[0]\n    for clip in video_clips[1:]:\n        video = concatenate_videoclips([video, clip], method=\"compose\")\n    \n    if audio_file and os.path.isfile(audio_file):\n        audio = AudioFileClip(audio_file)\n        video = video.set_audio(audio)\n    \n    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n    logging.info(f\"Video saved as {video_file}\")\n\ndef generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n    frames = generate_animated_frames(data)\n    if not frames:\n        raise ValueError(\"No frames generated from data.\")\n    \n    if os.path.exists(title_image):\n        title_image_clip = Image.open(title_image)\n        title_image_clip = title_image_clip.convert(\"RGBA\")\n        title_image_clip = np.array(title_image_clip)\n        frames.insert(0, title_image_clip)\n    \n    create_video_from_frames(frames, audio_file)\n    print(\"Video successfully generated!\")\n\ndef data_storytelling_pipeline(file_path, prompt, audio_file=None):\n    try:\n        start_time = time.time()\n        \n        logging.info(\"Loading and preprocessing data...\")\n        data = load_and_preprocess_data(file_path)\n        logging.debug(f\"Loaded Data: {data.head()}\")\n        \n        logging.info(\"Performing EDA...\")\n        eda_summary = perform_eda(data)\n        logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n        logging.info(\"Analyzing the user's prompt...\")\n        insights = analyze_prompt_for_insights(prompt)\n        logging.debug(f\"Extracted insights: {insights}\")\n        \n        logging.info(\"Creating the infographic video...\")\n        generate_infographic_video(data, insights, audio_file=audio_file)\n        \n        end_time = time.time()\n        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n    except FileNotFoundError as fnf_error:\n        logging.error(f\"File not found: {fnf_error}\")\n        raise\n    except pd.errors.ParserError as parser_error:\n        logging.error(f\"Error parsing the file: {parser_error}\")\n        raise\n    except TypeError as type_error:\n        logging.error(f\"Type error: {type_error}\")\n        raise\n    except ValueError as value_error:\n        logging.error(f\"Value error: {value_error}\")\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {e}\")\n        raise\n\n# Example usage:\nfile_path = '/kaggle/input/model-dataset-new-1/2015.csv'\nprompt = \"Analyze the country and region data\"\naudio_file = \"/kaggle/working/\"\ntitle_image = \"/kaggle/working/\"\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"Data file not found: {file_path}\")\nif not os.path.exists(audio_file):\n    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\nif not os.path.exists(title_image):\n    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\ndata_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:10.242392Z","iopub.execute_input":"2025-01-03T12:43:10.242633Z","iopub.status.idle":"2025-01-03T12:43:18.695945Z","shell.execute_reply.started":"2025-01-03T12:43:10.242612Z","shell.execute_reply":"2025-01-03T12:43:18.695177Z"}},"outputs":[{"name":"stdout","text":"Moviepy - Building video final_video.mp4.\nMoviepy - Writing video final_video.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready final_video.mp4\nVideo successfully generated!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport logging\nimport os\nfrom PIL import Image\nfrom moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip\nimport numpy as np\nimport io\nfrom matplotlib.animation import FuncAnimation\n\ndef generate_animated_frames(data):\n    logging.info(\"Generating animated frames from data\")\n    frames = []\n    \n    # Generate a basic time series plot if a date column is present\n    date_column = None\n    for col in data.columns:\n        if 'date' in col.lower() or 'time' in col.lower():\n            date_column = col\n            break\n    \n    if date_column:\n        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n        if len(numeric_columns) > 0:\n            fig, ax = plt.subplots(figsize=(10, 6))\n            lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n            ax.set_xlim(data[date_column].min(), data[date_column].max())\n            ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n            ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n            ax.set_xlabel('Time')\n            ax.set_ylabel('Values')\n            ax.legend()\n\n            def update(frame):\n                for line, col in zip(lines, numeric_columns):\n                    line.set_data(data[date_column][:frame], data[col][:frame])\n                return lines\n\n            ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n            for i in range(len(data)):\n                update(i)\n                buf = io.BytesIO()\n                fig.savefig(buf, format='png')\n                buf.seek(0)\n                img = Image.open(buf)\n                frames.append(img)\n            plt.close(fig)\n    \n    # Generate a correlation matrix plot\n    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n        corr_matrix = data.corr()\n        fig, ax = plt.subplots(figsize=(10, 6))\n        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n        ax.set_title('Correlation Matrix')\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(img)\n        plt.close(fig)\n    \n    # Generate distribution plots for numeric columns\n    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n    for col in numeric_columns:\n        fig, ax = plt.subplots(figsize=(8, 6))\n        sns.histplot(data[col], bins=10, kde=True, ax=ax)\n        ax.set_title(f\"Distribution of {col}\")\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(img)\n        plt.close(fig)\n    \n    logging.info(f\"Generated {len(frames)} animated frames\")\n    return frames\n\ndef create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n    if not frames:\n        raise ValueError(\"No frames to create video from.\")\n    \n    logging.info(\"Creating video from frames\")\n    video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n    # Add transitions between clips\n    def add_transition(clip1, clip2, duration=1):\n        return concatenate_videoclips([clip1.crossfadeout(duration), clip2.crossfadein(duration)], method=\"compose\")\n    \n    video = video_clips[0]\n    for clip in video_clips[1:]:\n        video = add_transition(video, clip)\n    \n    if audio_file and os.path.isfile(audio_file):\n        audio = AudioFileClip(audio_file)\n        video = video.set_audio(audio)\n    \n    video = video.set_duration(max(60, video.duration))  # Ensure video is at least 60 seconds long\n    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n    logging.info(f\"Video saved as {video_file}\")\n\ndef generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n    frames = generate_animated_frames(data)\n    if not frames:\n        raise ValueError(\"No frames generated from data.\")\n    \n    if os.path.exists(title_image):\n        title_image_clip = Image.open(title_image)\n        title_image_clip = title_image_clip.convert(\"RGBA\")\n        title_image_clip = np.array(title_image_clip)\n        frames.insert(0, title_image_clip)\n    \n    create_video_from_frames(frames, audio_file)\n    print(\"Video successfully generated!\")\n\ndef data_storytelling_pipeline(file_path, prompt, audio_file=None):\n    try:\n        start_time = time.time()\n        \n        logging.info(\"Loading and preprocessing data...\")\n        data = load_and_preprocess_data(file_path)\n        logging.debug(f\"Loaded Data: {data.head()}\")\n        \n        logging.info(\"Performing EDA...\")\n        eda_summary = perform_eda(data)\n        logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n        logging.info(\"Analyzing the user's prompt...\")\n        insights = analyze_prompt_for_insights(prompt)\n        logging.debug(f\"Extracted insights: {insights}\")\n        \n        logging.info(\"Creating the infographic video...\")\n        generate_infographic_video(data, insights, audio_file=audio_file)\n        \n        end_time = time.time()\n        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n    except FileNotFoundError as fnf_error:\n        logging.error(f\"File not found: {fnf_error}\")\n        raise\n    except pd.errors.ParserError as parser_error:\n        logging.error(f\"Error parsing the file: {parser_error}\")\n        raise\n    except TypeError as type_error:\n        logging.error(f\"Type error: {type_error}\")\n        raise\n    except ValueError as value_error:\n        logging.error(f\"Value error: {value_error}\")\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {e}\")\n        raise\n\n# Example usage:\nfile_path = '/kaggle/input/model-dataset-new-1/2015.csv'\nprompt = \"Analyze the country and region data\"\naudio_file = \"/kaggle/working/\"\ntitle_image = \"/kaggle/working/\"\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"Data file not found: {file_path}\")\nif not os.path.exists(audio_file):\n    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\nif not os.path.exists(title_image):\n    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\ndata_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:18.696758Z","iopub.execute_input":"2025-01-03T12:43:18.696990Z","iopub.status.idle":"2025-01-03T12:43:34.626151Z","shell.execute_reply.started":"2025-01-03T12:43:18.696956Z","shell.execute_reply":"2025-01-03T12:43:34.625248Z"}},"outputs":[{"name":"stdout","text":"Moviepy - Building video final_video.mp4.\nMoviepy - Writing video final_video.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready final_video.mp4\nVideo successfully generated!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n# import numpy as np\n# import io\n# from matplotlib.animation import FuncAnimation\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             for i in range(len(data)):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(img)\n#             plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n#     # Add transitions between clips\n#     def add_transition(clip1, clip2, duration=1):\n#         return concatenate_videoclips([clip1.crossfadeout(duration), clip2.crossfadein(duration)], method=\"compose\")\n    \n#     video = video_clips[0]\n#     for clip in video_clips[1:]:\n#         video = add_transition(video, clip)\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     # Add a title screen\n#     title = TextClip(\"Data Storytelling\", fontsize=70, color='white', bg_color='black', size=video.size)\n#     title = title.set_duration(3).fadein(1).fadeout(1)\n#     video = concatenate_videoclips([title, video])\n    \n#     video = video.set_duration(max(60, video.duration))  # Ensure video is at least 60 seconds long\n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.627049Z","iopub.execute_input":"2025-01-03T12:43:34.627343Z","iopub.status.idle":"2025-01-03T12:43:34.637150Z","shell.execute_reply.started":"2025-01-03T12:43:34.627315Z","shell.execute_reply":"2025-01-03T12:43:34.636476Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# !pip install imagemagick","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.637965Z","iopub.execute_input":"2025-01-03T12:43:34.638222Z","iopub.status.idle":"2025-01-03T12:43:34.656841Z","shell.execute_reply.started":"2025-01-03T12:43:34.638196Z","shell.execute_reply":"2025-01-03T12:43:34.656041Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n# import numpy as np\n# import io\n# from matplotlib.animation import FuncAnimation\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             for i in range(len(data)):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(img)\n#             plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n#     # Add transitions between clips\n#     def add_transition(clip1, clip2, duration=1):\n#         return concatenate_videoclips([clip1.crossfadeout(duration), clip2.crossfadein(duration)], method=\"compose\")\n    \n#     video = video_clips[0]\n#     for clip in video_clips[1:]:\n#         video = add_transition(video, clip)\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     # Add a title screen\n#     title = TextClip(\"Data Storytelling\", fontsize=70, color='white', bg_color='black', size=video.size)\n#     title = title.set_duration(3).fadein(1).fadeout(1)\n#     video = concatenate_videoclips([title, video])\n    \n#     video = video.set_duration(max(60, video.duration))  # Ensure video is at least 60 seconds long\n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.657548Z","iopub.execute_input":"2025-01-03T12:43:34.657780Z","iopub.status.idle":"2025-01-03T12:43:34.672309Z","shell.execute_reply.started":"2025-01-03T12:43:34.657748Z","shell.execute_reply":"2025-01-03T12:43:34.671394Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# import numpy as np\n# import io\n# from matplotlib.animation import FuncAnimation\n# import cv2\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             for i in range(len(data)):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(np.array(img))\n#             plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"new_final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     height, width, layers = frames[0].shape\n#     video = cv2.VideoWriter(video_file, cv2.VideoWriter_fourcc(*'mp4v'), 24, (width, height))\n    \n#     for frame in frames:\n#         video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n    \n#     video.release()\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.673142Z","iopub.execute_input":"2025-01-03T12:43:34.673471Z","iopub.status.idle":"2025-01-03T12:43:34.692178Z","shell.execute_reply.started":"2025-01-03T12:43:34.673441Z","shell.execute_reply":"2025-01-03T12:43:34.691140Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# import numpy as np\n# import io\n# from matplotlib.animation import FuncAnimation\n# import cv2\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             for i in range(len(data)):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(np.array(img))\n#             plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"second_final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     height, width, layers = frames[0].shape\n#     video = cv2.VideoWriter(video_file, cv2.VideoWriter_fourcc(*'mp4v'), 24, (width, height))\n    \n#     # Add a title screen\n#     title_screen = np.zeros((height, width, 3), dtype=np.uint8)\n#     title_screen.fill(0)  # Black background\n#     cv2.putText(title_screen, \"Data Storytelling\", (50, height // 2), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n#     for _ in range(72):  # 3 seconds at 24 fps\n#         video.write(title_screen)\n    \n#     for frame in frames:\n#         for _ in range(3):  # Repeat each frame to slow down the video\n#             video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n    \n#     # Ensure video is at least 60 seconds long\n#     while video.get(cv2.CAP_PROP_FRAME_COUNT) < 60 * 24:\n#         video.write(title_screen)\n    \n#     video.release()\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.692941Z","iopub.execute_input":"2025-01-03T12:43:34.693224Z","iopub.status.idle":"2025-01-03T12:43:34.704502Z","shell.execute_reply.started":"2025-01-03T12:43:34.693189Z","shell.execute_reply":"2025-01-03T12:43:34.703711Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# import numpy as np\n# import io\n# from matplotlib.animation import FuncAnimation\n# import cv2\n# import pandas as pd\n# import time\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data)//10, blit=True)\n#             for i in range(len(data)//10):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(np.array(img))\n#             plt.close(fig)\n    \n#     # Generate a moving bar chart\n#     if 'category' in data.columns and 'value' in data.columns:\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         categories = data['category'].unique()\n#         bars = ax.bar(categories, np.zeros(len(categories)))\n#         ax.set_ylim(0, data['value'].max())\n#         ax.set_title('Moving Bar Chart')\n#         ax.set_xlabel('Category')\n#         ax.set_ylabel('Value')\n\n#         def update_bar(frame):\n#             for bar, category in zip(bars, categories):\n#                 bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n#             return bars\n\n#         ani = FuncAnimation(fig, update_bar, frames=len(data)//10, blit=True)\n#         for i in range(len(data)//10):\n#             update_bar(i)\n#             buf = io.BytesIO()\n#             fig.savefig(buf, format='png')\n#             buf.seek(0)\n#             img = Image.open(buf)\n#             frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate a pairplot for numeric columns\n#     if len(numeric_columns) > 1:\n#         sns.pairplot(data[numeric_columns])\n#         plt.suptitle('Pairplot of Numeric Columns', y=1.02)\n#         buf = io.BytesIO()\n#         plt.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close()\n    \n#     # Generate a line plot for each numeric column\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         ax.plot(data.index, data[col])\n#         ax.set_title(f\"Line Plot of {col}\")\n#         ax.set_xlabel('Index')\n#         ax.set_ylabel(col)\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     height, width, layers = frames[0].shape\n#     video = cv2.VideoWriter(video_file, cv2.VideoWriter_fourcc(*'mp4v'), 24, (width, height))\n    \n#     for frame in frames:\n#         video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n    \n#     video.release()\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data_start_time = time.time()\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n#         logging.info(f\"Data loading and preprocessing took {time.time() - data_start_time:.2f} seconds\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_start_time = time.time()\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n#         logging.info(f\"EDA took {time.time() - eda_start_time:.2f} seconds\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         prompt_start_time = time.time()\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n#         logging.info(f\"Prompt analysis took {time.time() - prompt_start_time:.2f} seconds\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         video_start_time = time.time()\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n#         logging.info(f\"Video creation took {time.time() - video_start_time:.2f} seconds\")\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.705374Z","iopub.execute_input":"2025-01-03T12:43:34.705590Z","iopub.status.idle":"2025-01-03T12:43:34.720035Z","shell.execute_reply.started":"2025-01-03T12:43:34.705572Z","shell.execute_reply":"2025-01-03T12:43:34.719342Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import logging\nimport os\nimport pandas as pd\nimport time\nfrom moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport io\nfrom PIL import Image\nfrom matplotlib.animation import FuncAnimation\n\ndef generate_animated_bar_chart(data):\n    frames = []\n    fig, ax = plt.subplots(figsize=(10, 6))\n    categories = data['category'].unique()\n    bars = ax.bar(categories, np.zeros(len(categories)))\n    ax.set_ylim(0, data['value'].max())\n    ax.set_title('Moving Bar Chart')\n    ax.set_xlabel('Category')\n    ax.set_ylabel('Value')\n\n    def update_bar(frame):\n        for bar, category in zip(bars, categories):\n            bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n        return bars\n\n    ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n    for i in range(len(data)):\n        update_bar(i)\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(np.array(img))\n    plt.close(fig)\n    return frames\n\ndef generate_animated_correlation_matrix(data):\n    frames = []\n    corr_matrix = data.corr()\n    fig, ax = plt.subplots(figsize=(10, 6))\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n    ax.set_title('Correlation Matrix')\n    buf = io.BytesIO()\n    fig.savefig(buf, format='png')\n    buf.seek(0)\n    img = Image.open(buf)\n    frames.append(np.array(img))\n    plt.close(fig)\n    return frames\n\ndef generate_animated_frames(data):\n    logging.info(\"Generating animated frames from data\")\n    frames = []\n    \n    # Generate animated bar chart frames\n    if 'category' in data.columns and 'value' in data.columns:\n        frames.extend(generate_animated_bar_chart(data))\n    \n    # Generate animated correlation matrix frames\n    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n        frames.extend(generate_animated_correlation_matrix(data))\n    \n    logging.info(f\"Generated {len(frames)} animated frames\")\n    return frames\n\ndef create_video_from_frames(frames, audio_file=None, video_file=\"module_generation_seaborn.mp4\"):\n    if not frames:\n        raise ValueError(\"No frames to create video from.\")\n    \n    logging.info(\"Creating video from frames\")\n    video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n    video = concatenate_videoclips(video_clips, method=\"compose\")\n    \n    if audio_file and os.path.isfile(audio_file):\n        audio = AudioFileClip(audio_file)\n        video = video.set_audio(audio)\n    \n    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n    logging.info(f\"Video saved as {video_file}\")\n\ndef generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n    frames = generate_animated_frames(data)\n    if not frames:\n        raise ValueError(\"No frames generated from data.\")\n    \n    if os.path.exists(title_image):\n        title_image_clip = Image.open(title_image)\n        title_image_clip = title_image_clip.convert(\"RGBA\")\n        title_image_clip = np.array(title_image_clip)\n        frames.insert(0, title_image_clip)\n    \n    create_video_from_frames(frames, audio_file)\n    print(\"Video successfully generated!\")\n\ndef data_storytelling_pipeline(file_path, prompt, audio_file=None):\n    try:\n        start_time = time.time()\n        \n        logging.info(\"Loading and preprocessing data...\")\n        data = load_and_preprocess_data(file_path)\n        logging.debug(f\"Loaded Data: {data.head()}\")\n        \n        logging.info(\"Performing EDA...\")\n        eda_summary = perform_eda(data)\n        logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n        logging.info(\"Analyzing the user's prompt...\")\n        insights = analyze_prompt_for_insights(prompt)\n        logging.debug(f\"Extracted insights: {insights}\")\n        \n        logging.info(\"Creating the infographic video...\")\n        generate_infographic_video(data, insights, audio_file=audio_file)\n        \n        end_time = time.time()\n        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n    except FileNotFoundError as fnf_error:\n        logging.error(f\"File not found: {fnf_error}\")\n        raise\n    except pd.errors.ParserError as parser_error:\n        logging.error(f\"Error parsing the file: {parser_error}\")\n        raise\n    except TypeError as type_error:\n        logging.error(f\"Type error: {type_error}\")\n        raise\n    except ValueError as value_error:\n        logging.error(f\"Value error: {value_error}\")\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {e}\")\n        raise\n\n# Example usage:\nfile_path = '/kaggle/input/model-dataset-new-1/2015.csv'\nprompt = \"Analyze the country and region data\"\naudio_file = \"/kaggle/working/\"\ntitle_image = \"/kaggle/working/\"\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"Data file not found: {file_path}\")\nif not os.path.exists(audio_file):\n    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\nif not os.path.exists(title_image):\n    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\ndata_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.720783Z","iopub.execute_input":"2025-01-03T12:43:34.720981Z","iopub.status.idle":"2025-01-03T12:43:37.896066Z","shell.execute_reply.started":"2025-01-03T12:43:34.720964Z","shell.execute_reply":"2025-01-03T12:43:37.895195Z"}},"outputs":[{"name":"stdout","text":"Moviepy - Building video module_generation_seaborn.mp4.\nMoviepy - Writing video module_generation_seaborn.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                  ","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready module_generation_seaborn.mp4\nVideo successfully generated!\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport logging\nimport os\nfrom PIL import Image\nfrom moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\nimport numpy as np\nimport io\nimport pandas as pd\nimport time\n\ndef generate_default_frames(data):\n    logging.info(\"Generating default frames from data\")\n    frames = []\n    \n    # Generate a basic time series plot if a date column is present\n    date_column = None\n    for col in data.columns:\n        if 'date' in col.lower() or 'time' in col.lower():\n            date_column = col\n            break\n    \n    if date_column:\n        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n        if len(numeric_columns) > 0:\n            fig, ax = plt.subplots(figsize=(10, 6))\n            for col in numeric_columns:\n                ax.plot(data[date_column], data[col], label=col)\n            ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n            ax.set_xlabel('Time')\n            ax.set_ylabel('Values')\n            ax.legend()\n            buf = io.BytesIO()\n            fig.savefig(buf, format='png')\n            buf.seek(0)\n            img = Image.open(buf)\n            frames.append(img)\n            plt.close(fig)\n    \n    # Generate a correlation matrix plot\n    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n        corr_matrix = data.corr()\n        fig, ax = plt.subplots(figsize=(10, 6))\n        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n        ax.set_title('Correlation Matrix')\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(img)\n        plt.close(fig)\n    \n    # Generate distribution plots for numeric columns\n    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n    for col in numeric_columns:\n        fig, ax = plt.subplots(figsize=(8, 6))\n        sns.histplot(data[col], bins=10, kde=True, ax=ax)\n        ax.set_title(f\"Distribution of {col}\")\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(img)\n        plt.close(fig)\n    \n    logging.info(f\"Generated {len(frames)} default frames\")\n    return frames\n\ndef create_video_from_frames(frames, audio_file=None, video_file=\"frames_animations.mp4\"):\n    if not frames:\n        raise ValueError(\"No frames to create video from.\")\n    \n    logging.info(\"Creating video from frames\")\n    video_clips = []\n    for frame in frames:\n        img_clip = ImageSequenceClip([np.array(frame)], fps=1)  # 1 frame per second\n        img_clip = img_clip.set_duration(5)  # Each frame lasts 5 seconds\n        video_clips.append(img_clip)\n    \n    video = concatenate_videoclips(video_clips, method=\"compose\")\n    \n    if audio_file and os.path.isfile(audio_file):\n        audio = AudioFileClip(audio_file)\n        video = video.set_audio(audio)\n    \n    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n    logging.info(f\"Video saved as {video_file}\")\n\ndef generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n    frames = generate_default_frames(data)\n    if not frames:\n        raise ValueError(\"No frames generated from data.\")\n    \n    if os.path.exists(title_image):\n        title_image_clip = Image.open(title_image)\n        title_image_clip = title_image_clip.convert(\"RGBA\")\n        title_image_clip = np.array(title_image_clip)\n        frames.insert(0, title_image_clip)\n    \n    create_video_from_frames(frames, audio_file)\n    print(\"Video successfully generated!\")\n\ndef data_storytelling_pipeline(file_path, prompt, audio_file=None):\n    try:\n        start_time = time.time()\n        \n        logging.info(\"Loading and preprocessing data...\")\n        data = load_and_preprocess_data(file_path)\n        logging.debug(f\"Loaded Data: {data.head()}\")\n        \n        logging.info(\"Performing EDA...\")\n        eda_summary = perform_eda(data)\n        logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n        logging.info(\"Analyzing the user's prompt...\")\n        insights = analyze_prompt_for_insights(prompt)\n        logging.debug(f\"Extracted insights: {insights}\")\n        \n        logging.info(\"Creating the infographic video...\")\n        generate_infographic_video(data, insights, audio_file=audio_file)\n        \n        end_time = time.time()\n        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n    except FileNotFoundError as fnf_error:\n        logging.error(f\"File not found: {fnf_error}\")\n        raise\n    except pd.errors.ParserError as parser_error:\n        logging.error(f\"Error parsing the file: {parser_error}\")\n        raise\n    except TypeError as type_error:\n        logging.error(f\"Type error: {type_error}\")\n        raise\n    except ValueError as value_error:\n        logging.error(f\"Value error: {value_error}\")\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {e}\")\n        raise\n\n# Example usage:\nfile_path = '/kaggle/input/model-dataset-new-1/2015.csv'\nprompt = \"Analyze the country and region data\"\naudio_file = \"/kaggle/working/\"\ntitle_image = \"/kaggle/working/\"\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"Data file not found: {file_path}\")\nif not os.path.exists(audio_file):\n    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\nif not os.path.exists(title_image):\n    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\ndata_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:37.897085Z","iopub.execute_input":"2025-01-03T12:43:37.897431Z","iopub.status.idle":"2025-01-03T12:44:20.435197Z","shell.execute_reply.started":"2025-01-03T12:43:37.897401Z","shell.execute_reply":"2025-01-03T12:44:20.434365Z"}},"outputs":[{"name":"stdout","text":"Moviepy - Building video frames_animations.mp4.\nMoviepy - Writing video frames_animations.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                ","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready frames_animations.mp4\nVideo successfully generated!\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"!pip install gtts\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport logging\nimport os\nfrom PIL import Image\nfrom moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\nimport numpy as np\nimport io\nimport pandas as pd\nimport time\nfrom matplotlib.animation import FuncAnimation\nfrom gtts import gTTS\n\ndef generate_animated_frames(data):\n    logging.info(\"Generating animated frames from data\")\n    frames = []\n    \n    # Generate a basic time series plot if a date column is present\n    date_column = None\n    for col in data.columns:\n        if 'date' in col.lower() or 'time' in col.lower():\n            date_column = col\n            break\n    \n    if date_column:\n        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n        if len(numeric_columns) > 0:\n            fig, ax = plt.subplots(figsize=(10, 6))\n            lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n            ax.set_xlim(data[date_column].min(), data[date_column].max())\n            ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n            ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n            ax.set_xlabel('Time')\n            ax.set_ylabel('Values')\n            ax.legend()\n\n            def update(frame):\n                for line, col in zip(lines, numeric_columns):\n                    line.set_data(data[date_column][:frame], data[col][:frame])\n                return lines\n\n            ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n            for i in range(len(data)):\n                update(i)\n                buf = io.BytesIO()\n                fig.savefig(buf, format='png')\n                buf.seek(0)\n                img = Image.open(buf)\n                frames.append(np.array(img))\n            plt.close(fig)\n    \n    # Generate a moving bar chart\n    if 'category' in data.columns and 'value' in data.columns:\n        fig, ax = plt.subplots(figsize=(10, 6))\n        categories = data['category'].unique()\n        bars = ax.bar(categories, np.zeros(len(categories)))\n        ax.set_ylim(0, data['value'].max())\n        ax.set_title('Moving Bar Chart')\n        ax.set_xlabel('Category')\n        ax.set_ylabel('Value')\n\n        def update_bar(frame):\n            for bar, category in zip(bars, categories):\n                bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n            return bars\n\n        ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n        for i in range(len(data)):\n            update_bar(i)\n            buf = io.BytesIO()\n            fig.savefig(buf, format='png')\n            buf.seek(0)\n            img = Image.open(buf)\n            frames.append(np.array(img))\n        plt.close(fig)\n    \n    # Generate a correlation matrix plot\n    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n        corr_matrix = data.corr()\n        fig, ax = plt.subplots(figsize=(10, 6))\n        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n        ax.set_title('Correlation Matrix')\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(np.array(img))\n        plt.close(fig)\n    \n    # Generate distribution plots for numeric columns\n    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n    for col in numeric_columns:\n        fig, ax = plt.subplots(figsize=(8, 6))\n        sns.histplot(data[col], bins=10, kde=True, ax=ax)\n        ax.set_title(f\"Distribution of {col}\")\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(np.array(img))\n        plt.close(fig)\n    \n    logging.info(f\"Generated {len(frames)} animated frames\")\n    return frames\n\ndef create_video_from_frames(frames, audio_file=None, video_file=\"composition_model.mp4\"):\n    if not frames:\n        raise ValueError(\"No frames to create video from.\")\n    \n    logging.info(\"Creating video from frames\")\n    video_clips = []\n    for frame in frames:\n        img_clip = ImageSequenceClip([frame], fps=1)  # 1 frame per second\n        img_clip = img_clip.set_duration(2)  # Each frame lasts 2 seconds\n        video_clips.append(img_clip)\n    \n    video = concatenate_videoclips(video_clips, method=\"compose\")\n    \n    if audio_file and os.path.isfile(audio_file):\n        audio = AudioFileClip(audio_file)\n        video = video.set_audio(audio)\n    \n    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n    logging.info(f\"Video saved as {video_file}\")\n\ndef generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n    frames = generate_animated_frames(data)\n    if not frames:\n        raise ValueError(\"No frames generated from data.\")\n    \n    if os.path.exists(title_image):\n        title_image_clip = Image.open(title_image)\n        title_image_clip = title_image_clip.convert(\"RGBA\")\n        title_image_clip = np.array(title_image_clip)\n        frames.insert(0, title_image_clip)\n    \n    create_video_from_frames(frames, audio_file)\n    print(\"Video successfully generated!\")\n\ndef generate_narration(text, output_file=\"narration.mp3\"):\n    tts = gTTS(text=text, lang='en')\n    tts.save(output_file)\n    return output_file\n\ndef data_storytelling_pipeline(file_path, prompt, audio_file=None):\n    try:\n        start_time = time.time()\n        \n        logging.info(\"Loading and preprocessing data...\")\n        data = load_and_preprocess_data(file_path)\n        logging.debug(f\"Loaded Data: {data.head()}\")\n        \n        logging.info(\"Performing EDA...\")\n        eda_summary = perform_eda(data)\n        logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n        logging.info(\"Analyzing the user's prompt...\")\n        insights = analyze_prompt_for_insights(prompt)\n        logging.debug(f\"Extracted insights: {insights}\")\n        \n        logging.info(\"Generating narration...\")\n        narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n        narration_file = generate_narration(narration_text)\n        \n        logging.info(\"Creating the infographic video...\")\n        generate_infographic_video(data, insights, audio_file=narration_file)\n        \n        end_time = time.time()\n        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n    except FileNotFoundError as fnf_error:\n        logging.error(f\"File not found: {fnf_error}\")\n        raise\n    except pd.errors.ParserError as parser_error:\n        logging.error(f\"Error parsing the file: {parser_error}\")\n        raise\n    except TypeError as type_error:\n        logging.error(f\"Type error: {type_error}\")\n        raise\n    except ValueError as value_error:\n        logging.error(f\"Value error: {value_error}\")\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {e}\")\n        raise\n\n# Example usage:\nfile_path = '/kaggle/input/model-dataset-new-1/2015.csv'\nprompt = \"Analyze the country and region data\"\naudio_file = \"/kaggle/working/\"\ntitle_image = \"/kaggle/working/\"\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"Data file not found: {file_path}\")\nif not os.path.exists(audio_file):\n    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\nif not os.path.exists(title_image):\n    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\ndata_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:53:44.074549Z","iopub.execute_input":"2025-01-03T12:53:44.074878Z","iopub.status.idle":"2025-01-03T12:54:11.542653Z","shell.execute_reply.started":"2025-01-03T12:53:44.074852Z","shell.execute_reply":"2025-01-03T12:54:11.541793Z"}},"outputs":[{"name":"stdout","text":"Collecting gtts\n  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\nRequirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\nDownloading gTTS-2.5.4-py3-none-any.whl (29 kB)\nInstalling collected packages: gtts\nSuccessfully installed gtts-2.5.4\nMoviepy - Building video composition_model.mp4.\nMoviePy - Writing audio in composition_modelTEMP_MPY_wvf_snd.mp3\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\nMoviepy - Writing video composition_model.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready composition_model.mp4\nVideo successfully generated!\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport logging\nimport os\nfrom PIL import Image\nfrom moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\nimport numpy as np\nimport io\nimport pandas as pd\nimport time\nfrom matplotlib.animation import FuncAnimation\nfrom gtts import gTTS\n\ndef generate_animated_gifs(data):\n    logging.info(\"Generating animated GIFs from data\")\n    gif_files = []\n    \n    # Generate a basic time series plot if a date column is present\n    date_column = None\n    for col in data.columns:\n        if 'date' in col.lower() or 'time' in col.lower():\n            date_column = col\n            break\n    \n    if date_column:\n        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n        if len(numeric_columns) > 0:\n            fig, ax = plt.subplots(figsize=(10, 6))\n            lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n            ax.set_xlim(data[date_column].min(), data[date_column].max())\n            ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n            ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n            ax.set_xlabel('Time')\n            ax.set_ylabel('Values')\n            ax.legend()\n\n            def update(frame):\n                for line, col in zip(lines, numeric_columns):\n                    line.set_data(data[date_column][:frame], data[col][:frame])\n                return lines\n\n            ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n            gif_file = \"time_series.gif\"\n            ani.save(gif_file, writer='imagemagick')\n            gif_files.append(gif_file)\n            plt.close(fig)\n    \n    # Generate a moving bar chart\n    if 'category' in data.columns and 'value' in data.columns:\n        fig, ax = plt.subplots(figsize=(10, 6))\n        categories = data['category'].unique()\n        bars = ax.bar(categories, np.zeros(len(categories)))\n        ax.set_ylim(0, data['value'].max())\n        ax.set_title('Moving Bar Chart')\n        ax.set_xlabel('Category')\n        ax.set_ylabel('Value')\n\n        def update_bar(frame):\n            for bar, category in zip(bars, categories):\n                bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n            return bars\n\n        ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n        gif_file = \"moving_bar_chart.gif\"\n        ani.save(gif_file, writer='imagemagick')\n        gif_files.append(gif_file)\n        plt.close(fig)\n    \n    # Generate a correlation matrix plot\n    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n        corr_matrix = data.corr()\n        fig, ax = plt.subplots(figsize=(10, 6))\n        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n        ax.set_title('Correlation Matrix')\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        img.save(\"correlation_matrix.png\")\n        gif_files.append(\"correlation_matrix.png\")\n        plt.close(fig)\n    \n    # Generate distribution plots for numeric columns\n    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n    for col in numeric_columns:\n        fig, ax = plt.subplots(figsize=(8, 6))\n        sns.histplot(data[col], bins=10, kde=True, ax=ax)\n        ax.set_title(f\"Distribution of {col}\")\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        img.save(f\"distribution_{col}.png\")\n        gif_files.append(f\"distribution_{col}.png\")\n        plt.close(fig)\n    \n    logging.info(f\"Generated {len(gif_files)} animated GIFs and images\")\n    return gif_files\n\ndef create_video_from_gifs(gif_files, audio_file=None, video_file=\"gif_composition_video.mp4\"):\n    if not gif_files:\n        raise ValueError(\"No GIF files to create video from.\")\n    \n    logging.info(\"Creating video from GIF files\")\n    video_clips = []\n    for gif_file in gif_files:\n        if gif_file.endswith('.gif'):\n            img_clip = ImageSequenceClip(gif_file, fps=1)  # 1 frame per second\n        else:\n            img_clip = ImageSequenceClip([gif_file], fps=1)  # 1 frame per second\n        img_clip = img_clip.set_duration(5)  # Each frame lasts 5 seconds\n        video_clips.append(img_clip)\n    \n    video = concatenate_videoclips(video_clips, method=\"compose\")\n    \n    if audio_file and os.path.isfile(audio_file):\n        audio = AudioFileClip(audio_file)\n        video = video.set_audio(audio)\n    \n    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n    logging.info(f\"Video saved as {video_file}\")\n\ndef generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n    gif_files = generate_animated_gifs(data)\n    if not gif_files:\n        raise ValueError(\"No GIF files generated from data.\")\n    \n    if os.path.exists(title_image):\n        gif_files.insert(0, title_image)\n    \n    create_video_from_gifs(gif_files, audio_file)\n    print(\"Video successfully generated!\")\n\ndef generate_narration(text, output_file=\"narration.mp3\"):\n    tts = gTTS(text=text, lang='en')\n    tts.save(output_file)\n    return output_file\n\ndef data_storytelling_pipeline(file_path, prompt, audio_file=None):\n    try:\n        start_time = time.time()\n        \n        logging.info(\"Loading and preprocessing data...\")\n        data = load_and_preprocess_data(file_path)\n        logging.debug(f\"Loaded Data: {data.head()}\")\n        \n        logging.info(\"Performing EDA...\")\n        eda_summary = perform_eda(data)\n        logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n        logging.info(\"Analyzing the user's prompt...\")\n        insights = analyze_prompt_for_insights(prompt)\n        logging.debug(f\"Extracted insights: {insights}\")\n        \n        logging.info(\"Generating narration...\")\n        narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n        narration_file = generate_narration(narration_text)\n        \n        logging.info(\"Creating the infographic video...\")\n        generate_infographic_video(data, insights, audio_file=narration_file)\n        \n        end_time = time.time()\n        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n    except FileNotFoundError as fnf_error:\n        logging.error(f\"File not found: {fnf_error}\")\n        raise\n    except pd.errors.ParserError as parser_error:\n        logging.error(f\"Error parsing the file: {parser_error}\")\n        raise\n    except TypeError as type_error:\n        logging.error(f\"Type error: {type_error}\")\n        raise\n    except ValueError as value_error:\n        logging.error(f\"Value error: {value_error}\")\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {e}\")\n        raise\n\n# Example usage:\nfile_path = '/kaggle/input/model-dataset-new-1/2015.csv'\nprompt = \"Analyze the country and region data\"\naudio_file = \"/kaggle/working/\"\ntitle_image = \"/kaggle/working/\"\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"Data file not found: {file_path}\")\nif not os.path.exists(audio_file):\n    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\nif not os.path.exists(title_image):\n    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\ndata_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:54:11.544170Z","iopub.execute_input":"2025-01-03T12:54:11.544572Z","iopub.status.idle":"2025-01-03T12:54:56.959405Z","shell.execute_reply.started":"2025-01-03T12:54:11.544548Z","shell.execute_reply":"2025-01-03T12:54:56.958529Z"}},"outputs":[{"name":"stdout","text":"Moviepy - Building video gif_composition_video.mp4.\nMoviePy - Writing audio in gif_composition_videoTEMP_MPY_wvf_snd.mp3\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\nMoviepy - Writing video gif_composition_video.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready gif_composition_video.mp4\nVideo successfully generated!\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport logging\nimport os\nfrom PIL import Image\nfrom moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\nimport numpy as np\nimport io\nimport pandas as pd\nimport time\nfrom matplotlib.animation import FuncAnimation\nfrom gtts import gTTS\n\ndef generate_animated_frames(data):\n    logging.info(\"Generating animated frames from data\")\n    frames = []\n    \n    # Generate a basic time series plot if a date column is present\n    date_column = None\n    for col in data.columns:\n        if 'date' in col.lower() or 'time' in col.lower():\n            date_column = col\n            break\n    \n    if date_column:\n        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n        if len(numeric_columns) > 0:\n            fig, ax = plt.subplots(figsize=(10, 6))\n            lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n            ax.set_xlim(data[date_column].min(), data[date_column].max())\n            ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n            ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n            ax.set_xlabel('Time')\n            ax.set_ylabel('Values')\n            ax.legend()\n\n            def update(frame):\n                for line, col in zip(lines, numeric_columns):\n                    line.set_data(data[date_column][:frame], data[col][:frame])\n                return lines\n\n            ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n            for i in range(len(data)):\n                update(i)\n                buf = io.BytesIO()\n                fig.savefig(buf, format='png')\n                buf.seek(0)\n                img = Image.open(buf)\n                frames.append(np.array(img))\n            plt.close(fig)\n    \n    # Generate an animated bar chart\n    if 'category' in data.columns and 'value' in data.columns:\n        fig, ax = plt.subplots(figsize=(10, 6))\n        categories = data['category'].unique()\n        bars = ax.bar(categories, np.zeros(len(categories)))\n        ax.set_ylim(0, data['value'].max())\n        ax.set_title('Animated Bar Chart')\n        ax.set_xlabel('Category')\n        ax.set_ylabel('Value')\n\n        def update_bar(frame):\n            for bar, category in zip(bars, categories):\n                bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n            return bars\n\n        ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n        for i in range(len(data)):\n            update_bar(i)\n            buf = io.BytesIO()\n            fig.savefig(buf, format='png')\n            buf.seek(0)\n            img = Image.open(buf)\n            frames.append(np.array(img))\n        plt.close(fig)\n    \n    # Generate an animated pie chart\n    if 'category' in data.columns and 'value' in data.columns:\n        fig, ax = plt.subplots(figsize=(10, 6))\n        def update_pie(frame):\n            ax.clear()\n            ax.pie(data['value'][:frame], labels=data['category'][:frame], autopct='%1.1f%%')\n            ax.set_title('Animated Pie Chart')\n\n        ani = FuncAnimation(fig, update_pie, frames=len(data), blit=True)\n        for i in range(len(data)):\n            update_pie(i)\n            buf = io.BytesIO()\n            fig.savefig(buf, format='png')\n            buf.seek(0)\n            img = Image.open(buf)\n            frames.append(np.array(img))\n        plt.close(fig)\n    \n    # Generate a correlation matrix plot\n    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n        corr_matrix = data.corr()\n        fig, ax = plt.subplots(figsize=(10, 6))\n        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n        ax.set_title('Correlation Matrix')\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(np.array(img))\n        plt.close(fig)\n    \n    # Generate distribution plots for numeric columns\n    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n    for col in numeric_columns:\n        fig, ax = plt.subplots(figsize=(8, 6))\n        sns.histplot(data[col], bins=10, kde=True, ax=ax)\n        ax.set_title(f\"Distribution of {col}\")\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(np.array(img))\n        plt.close(fig)\n    \n    logging.info(f\"Generated {len(frames)} animated frames\")\n    return frames\n\ndef create_video_from_frames(frames, audio_file=None, video_file=\"gif_new_composition.mp4\"):\n    if not frames:\n        raise ValueError(\"No frames to create video from.\")\n    \n    logging.info(\"Creating video from frames\")\n    video_clips = []\n    for frame in frames:\n        img_clip = ImageSequenceClip([frame], fps=1)  # 1 frame per second\n        img_clip = img_clip.set_duration(2)  # Each frame lasts 2 seconds\n        video_clips.append(img_clip)\n    \n    video = concatenate_videoclips(video_clips, method=\"compose\")\n    \n    if audio_file and os.path.isfile(audio_file):\n        audio = AudioFileClip(audio_file)\n        video = video.set_audio(audio)\n    \n    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n    logging.info(f\"Video saved as {video_file}\")\n\ndef generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n    frames = generate_animated_frames(data)\n    if not frames:\n        raise ValueError(\"No frames generated from data.\")\n    \n    if os.path.exists(title_image):\n        title_image_clip = Image.open(title_image)\n        title_image_clip = title_image_clip.convert(\"RGBA\")\n        title_image_clip = np.array(title_image_clip)\n        frames.insert(0, title_image_clip)\n    \n    create_video_from_frames(frames, audio_file)\n    print(\"Video successfully generated!\")\n\ndef generate_narration(text, output_file=\"narration.mp3\"):\n    tts = gTTS(text=text, lang='en')\n    tts.save(output_file)\n    return output_file\n\ndef data_storytelling_pipeline(file_path, prompt, audio_file=None):\n    try:\n        start_time = time.time()\n        \n        logging.info(\"Loading and preprocessing data...\")\n        data = load_and_preprocess_data(file_path)\n        logging.debug(f\"Loaded Data: {data.head()}\")\n        \n        logging.info(\"Performing EDA...\")\n        eda_summary = perform_eda(data)\n        logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n        logging.info(\"Analyzing the user's prompt...\")\n        insights = analyze_prompt_for_insights(prompt)\n        logging.debug(f\"Extracted insights: {insights}\")\n        \n        logging.info(\"Generating narration...\")\n        narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n        narration_file = generate_narration(narration_text)\n        \n        logging.info(\"Creating the infographic video...\")\n        generate_infographic_video(data, insights, audio_file=narration_file)\n        \n        end_time = time.time()\n        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n    except FileNotFoundError as fnf_error:\n        logging.error(f\"File not found: {fnf_error}\")\n        raise\n    except pd.errors.ParserError as parser_error:\n        logging.error(f\"Error parsing the file: {parser_error}\")\n        raise\n    except TypeError as type_error:\n        logging.error(f\"Type error: {type_error}\")\n        raise\n    except ValueError as value_error:\n        logging.error(f\"Value error: {value_error}\")\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {e}\")\n        raise\n\n# Example usage:\nfile_path = '/kaggle/input/model-dataset-new-1/2017.csv'\nprompt = \"compare the family and generaosity in an interactive video format\"\naudio_file = \"/kaggle/working/\"\ntitle_image = \"/kaggle/working/\"\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"Data file not found: {file_path}\")\nif not os.path.exists(audio_file):\n    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\nif not os.path.exists(title_image):\n    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\ndata_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T19:52:12.773280Z","iopub.execute_input":"2025-01-03T19:52:12.773600Z","iopub.status.idle":"2025-01-03T19:52:57.721588Z","shell.execute_reply.started":"2025-01-03T19:52:12.773577Z","shell.execute_reply":"2025-01-03T19:52:57.720737Z"}},"outputs":[{"name":"stdout","text":"Moviepy - Building video data_storytelling_video.mp4.\nMoviePy - Writing audio in data_storytelling_videoTEMP_MPY_wvf_snd.mp3\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\nMoviepy - Writing video data_storytelling_video.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready data_storytelling_video.mp4\nVideo successfully generated!\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"import plotly.express as px\nimport pandas as pd\nimport logging\nimport os\nimport time\nfrom moviepy.editor import ImageSequenceClip, concatenate_videoclips, AudioFileClip, VideoFileClip\nfrom gtts import gTTS\nfrom transformers import BartTokenizer, BartForConditionalGeneration\nimport spacy\nimport re\nfrom sklearn.preprocessing import StandardScaler\n\n# Setting up logging\nlogging.basicConfig(level=logging.INFO)\n\n# Load spaCy model for NER\nnlp = spacy.load(\"en_core_web_sm\")\nimport plotly.express as px\nimport pandas as pd\nimport logging\nimport os\nimport time\nfrom moviepy.editor import ImageSequenceClip, concatenate_videoclips, AudioFileClip, VideoFileClip\nfrom gtts import gTTS\nfrom transformers import BartTokenizer, BartForConditionalGeneration\nimport spacy\nimport re\nfrom sklearn.preprocessing import StandardScaler\n\n# Setting up logging\nlogging.basicConfig(level=logging.INFO)\n\n# Load spaCy model for NER\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef load_and_preprocess_data(file_path):\n    try:\n        logging.info(f\"Loading data from {file_path}\")\n        print(f\"Loading data from {file_path}\")\n        # Load data\n        if file_path.endswith('.csv'):\n            data = pd.read_csv(file_path)\n        elif file_path.endswith('.xlsx'):\n            data = pd.read_excel(file_path)\n        elif file_path.endswith('.txt'):\n            data = pd.read_csv(file_path, delimiter='\\t')\n        else:\n            raise ValueError(\"Unsupported file format.\")\n        \n        logging.info(\"Data loaded successfully\")\n        print(\"Data loaded successfully\")\n        \n        # Detect and convert data types\n        for col in data.columns:\n            try:\n                data[col] = pd.to_numeric(data[col], errors='coerce')\n            except ValueError:\n                pass\n        \n        # Handle missing values\n        data.fillna(data.mean(), inplace=True)\n        \n        # Handle categorical data\n        categorical_cols = data.select_dtypes(include=['object']).columns\n        data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n        \n        # Normalize numeric data\n        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n        scaler = StandardScaler()\n        data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n        \n        # Add default columns if missing\n        if 'date' not in data.columns:\n            data['date'] = pd.date_range(start='1/1/2020', periods=len(data), freq='D')\n        if 'value' not in data.columns:\n            data['value'] = 1  # Default value\n        if 'category' not in data.columns:\n            data['category'] = 'default_category'\n        \n        logging.info(\"Data preprocessing completed\")\n        print(\"Data preprocessing completed\")\n        return data\n    except Exception as e:\n        logging.error(f\"Error loading and preprocessing data: {e}\")\n        print(f\"Error loading and preprocessing data: {e}\")\n        raise\n\n# The rest of the code remains the same\n\ndef infer_columns(data):\n    try:\n        column_mapping = {}\n        possible_columns = {\n            'category': ['category', 'type', 'class', 'label', 'country', 'region'],\n            'value': ['value', 'amount', 'score', 'total', 'family', 'generosity'],\n            'date': ['date', 'time', 'year', 'month', 'day'],\n            'x': ['x', 'longitude', 'lat', 'latitude'],\n            'y': ['y', 'latitude', 'long', 'longitude']\n        }\n        \n        logging.info(f\"Data columns: {data.columns.tolist()}\")\n        print(f\"Data columns: {data.columns.tolist()}\")\n        for key, patterns in possible_columns.items():\n            for pattern in patterns:\n                potential_cols = [col for col in data.columns if re.search(pattern, col, re.IGNORECASE)]\n                if potential_cols:\n                    column_mapping[key] = potential_cols[0]\n                    break\n        \n        # If any required column is missing, attempt to infer it\n        if 'date' not in column_mapping:\n            data['date'] = pd.date_range(start='1/1/2020', periods=len(data), freq='D')\n            column_mapping['date'] = 'date'\n        \n        if 'value' not in column_mapping:\n            numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n            if len(numeric_cols) > 0:\n                column_mapping['value'] = numeric_cols[0]\n            else:\n                raise ValueError(\"Cannot infer 'value' column.\")\n        \n        if 'category' not in column_mapping:\n            categorical_cols = data.select_dtypes(include=['object']).columns\n            if len(categorical_cols) > 0:\n                column_mapping['category'] = categorical_cols[0]\n            else:\n                non_numeric_cols = data.select_dtypes(exclude=['float64', 'int64']).columns\n                if len(non_numeric_cols) > 0:\n                    column_mapping['category'] = non_numeric_cols[0]\n                else:\n                    raise ValueError(\"Cannot infer 'category' column.\")\n        \n        return column_mapping\n    except Exception as e:\n        logging.error(f\"Error inferring columns: {e}\")\n        print(f\"Error inferring columns: {e}\")\n        raise\n\ndef generate_frames(data, chart_type, column_mapping, output_dir=\"frames\"):\n    try:\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        \n        frames = []\n        for date in data[column_mapping['date']].unique():\n            filtered_data = data[data[column_mapping['date']] == date]\n            if chart_type == 'bar':\n                fig = px.bar(filtered_data, x=column_mapping['category'], y=column_mapping['value'], title=f\"Bar Chart - {date}\")\n            elif chart_type == 'pie':\n                fig = px.pie(filtered_data, values=column_mapping['value'], names=column_mapping['category'], title=f\"Pie Chart - {date}\")\n            elif chart_type == 'scatter':\n                fig = px.scatter(filtered_data, x=column_mapping['x'], y=column_mapping['y'], size=column_mapping['value'], color=column_mapping['category'], title=f\"Scatter Plot - {date}\")\n            else:\n                raise ValueError(\"Invalid chart type\")\n            \n            frame_path = os.path.join(output_dir, f\"{chart_type}_{date}.png\")\n            fig.write_image(frame_path)\n            frames.append(frame_path)\n        \n        return frames\n    except Exception as e:\n        logging.error(f\"Error generating frames: {e}\")\n        print(f\"Error generating frames: {e}\")\n        raise\n\ndef generate_video_from_frames(frames, output_file=\"animation.mp4\", fps=1):\n    try:\n        clip = ImageSequenceClip(frames, fps=fps)\n        clip.write_videofile(output_file, codec=\"libx264\")\n        return output_file\n    except Exception as e:\n        logging.error(f\"Error generating video from frames: {e}\")\n        print(f\"Error generating video from frames: {e}\")\n        raise\n\ndef generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n    try:\n        logging.info(\"Checking data columns for required visualizations\")\n        print(\"Checking data columns for required visualizations\")\n        column_mapping = infer_columns(data)\n        logging.debug(f\"Column mapping: {column_mapping}\")\n        print(f\"Column mapping: {column_mapping}\")\n        video_files = generate_videos_if_needed(data, column_mapping)\n        \n        if not video_files:\n            logging.error(\"No video files generated from data. Check if the data has the required columns.\")\n            print(\"No video files generated from data. Check if the data has the required columns.\")\n            raise ValueError(\"No video files generated from data.\")\n        \n        logging.info(\"Combining video files into a single video\")\n        print(\"Combining video files into a single video\")\n        video_clips = [VideoFileClip(video_file) for video_file in video_files]\n        \n        if os.path.exists(title_image):\n            title_clip = VideoFileClip(title_image).set_duration(5)\n            video_clips.insert(0, title_clip)\n        \n        final_video = concatenate_videoclips(video_clips, method=\"compose\")\n        \n        if audio_file and os.path.isfile(audio_file):\n            audio = AudioFileClip(audio_file)\n            final_video = final_video.set_audio(audio)\n        \n        final_video.write_videofile(\"attemot_video.mp4\", codec=\"libx264\", fps=24)\n        logging.info(\"Final video saved as final_video.mp4\")\n        print(\"Final video saved as final_video.mp4\")\n    except Exception as e:\n        logging.error(f\"Error generating infographic video: {e}\")\ndef generate_videos_if_needed(data, column_mapping):\n        raise\n\ndef generate_videos_if_needed(data):\n    try:\n        video_files = []\n        column_mapping = infer_columns(data)\n        required_columns = {'category', 'value', 'date'}\n        if not required_columns.issubset(column_mapping.keys()):\n            logging.error(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n            print(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n            raise ValueError(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n\n        if required_columns.issubset(column_mapping.keys()):\n            logging.info(\"Data contains required columns for bar and pie charts\")\n            print(\"Data contains required columns for bar and pie charts\")\n            try:\n                bar_frames = generate_frames(data, 'bar', column_mapping)\n                video_files.append(generate_video_from_frames(bar_frames, \"animated_bar_chart.mp4\"))\n            except Exception as e:\n                logging.error(f\"Failed to generate animated bar chart: {e}\")\n                print(f\"Failed to generate animated bar chart: {e}\")\n            try:\n                pie_frames = generate_frames(data, 'pie', column_mapping)\n                video_files.append(generate_video_from_frames(pie_frames, \"animated_pie_chart.mp4\"))\n            except Exception as e:\n                logging.error(f\"Failed to generate animated pie chart: {e}\")\n                print(f\"Failed to generate animated pie chart: {e}\")\n        if {'x', 'y', 'value', 'date'}.issubset(column_mapping.keys()):\n            logging.info(\"Data contains required columns for scatter plot\")\n            print(\"Data contains required columns for scatter plot\")\n            try:\n                scatter_frames = generate_frames(data, 'scatter', column_mapping)\n                video_files.append(generate_video_from_frames(scatter_frames, \"animated_scatter_plot.mp4\"))\n            except Exception as e:\n                logging.error(f\"Failed to generate animated scatter plot: {e}\")\n                print(f\"Failed to generate animated scatter plot: {e}\")\n        return video_files\n    except Exception as e:\n        logging.error(f\"Error generating videos if needed: {e}\")\n        print(f\"Error generating videos if needed: {e}\")\n        raise\n\ndef generate_narration(text, output_file=\"narration.mp3\"):\n    try:\n        tts = gTTS(text=text, lang='en')\n        tts.save(output_file)\n        return output_file\n    except Exception as e:\n        logging.error(f\"Error generating narration: {e}\")\n        print(f\"Error generating narration: {e}\")\n        raise\n\ndef perform_eda(data):\n    try:\n        eda_summary = {\n            \"shape\": data.shape,\n            \"columns\": data.columns.tolist(),\n            \"dtypes\": data.dtypes.tolist(),\n            \"null_counts\": data.isnull().sum().tolist(),\n            \"describe\": data.describe().to_dict()\n        }\n        return eda_summary\n    except Exception as e:\n        logging.error(f\"Error performing EDA: {e}\")\n        print(f\"Error performing EDA: {e}\")\n        raise\n\ndef analyze_prompt_for_insights(prompt, model_name=\"facebook/bart-large\"):\n    try:\n        logging.info(\"Analyzing prompt for insights\")\n        print(\"Analyzing prompt for insights\")\n        tokenizer = BartTokenizer.from_pretrained(model_name)\n        model = BartForConditionalGeneration.from_pretrained(model_name)\n        \n        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n        input_ids = inputs.input_ids\n        attention_mask = inputs.attention_mask\n        \n        outputs = model.generate(\n            input_ids,\n            attention_mask=attention_mask,\n            max_length=200,\n            num_return_sequences=1,\n            temperature=0.7,\n            top_p=0.9,\n            top_k=50,\n            no_repeat_ngram_size=2,\n            pad_token_id=tokenizer.eos_token_id\n        )\n        \n        generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n        insights = extract_insights_from_text(generated_text)\n        \n        insights_list = [key for key, value in insights.items() if value]\n        if not insights_list:\n            logging.warning(\"No insights could be extracted from the provided prompt. Using default insights.\")\n            print(\"No insights could be extracted from the provided prompt. Using default insights.\")\n            insights_list = [\"trend\", \"comparison\"]\n        \n        logging.info(f\"Insights extracted: {insights_list}\")\n        print(f\"Insights extracted: {insights_list}\")\n        return insights_list\n    except Exception as e:\n        logging.error(f\"Error in analyzing prompt for insights: {e}\")\n        print(f\"Error in analyzing prompt for insights: {e}\")\n        return [\"trend\", \"comparison\"]\n\ndef data_storytelling_pipeline(file_path, prompt, audio_file=None):\n    try:\n        start_time = time.time()\n        \n        logging.info(\"Loading and preprocessing data...\")\n        print(\"Loading and preprocessing data...\")\n        data = load_and_preprocess_data(file_path)\n        logging.debug(f\"Loaded Data: {data.head()}\")\n        print(f\"Loaded Data: {data.head()}\")\n        \n        logging.info(\"Performing EDA...\")\n        print(\"Performing EDA...\")\n        eda_summary = perform_eda(data)\n        logging.debug(f\"EDA Summary: {eda_summary}\")\n        print(f\"EDA Summary: {eda_summary}\")\n        \n        logging.info(\"Analyzing the user's prompt...\")\n        print(\"Analyzing the user's prompt...\")\n        insights = analyze_prompt_for_insights(prompt)\n        logging.debug(f\"Extracted insights: {insights}\")\n        print(f\"Extracted insights: {insights}\")\n        \n        logging.info(\"Generating narration...\")\n        print(\"Generating narration...\")\n        narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n        narration_file = generate_narration(narration_text)\n        \n        logging.info(\"Creating the infographic video...\")\n        print(\"Creating the infographic video...\")\n        generate_infographic_video(data, insights, audio_file=narration_file)\n        \n        end_time = time.time()\n        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n        print(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n    except FileNotFoundError as fnf_error:\n        logging.error(f\"File not found: {fnf_error}\")\n        print(f\"File not found: {fnf_error}\")\n        raise\n    except pd.errors.ParserError as parser_error:\n        logging.error(f\"Error parsing the file: {parser_error}\")\n        print(f\"Error parsing the file: {parser_error}\")\n        raise\n    except TypeError as type_error:\n        logging.error(f\"Type error: {type_error}\")\n        print(f\"Type error: {type_error}\")\n        raise\n    except ValueError as value_error:\n        logging.error(f\"Value error: {value_error}\")\n        print(f\"Value error: {value_error}\")\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {e}\")\n        print(f\"An unexpected error occurred: {e}\")\n        raise\n\n# Example usage:\nfile_path = '/kaggle/input/model-dataset-new-1/2017.csv'\nprompt = \"analyse the family and generaosity columns data in the video format\"\naudio_file = \"/kaggle/working/\"\ntitle_image = \"/kaggle/working/\"\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"Data file not found: {file_path}\")\nif not os.path.exists(audio_file):\n    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\nif not os.path.exists(title_image):\n    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\ntry:\n    data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\nexcept ValueError as e:\n    if \"Missing required columns\" in str(e):\n        logging.info(\"Adding missing columns to the data\")\n        print(\"Adding missing columns to the data\")\n        data = load_and_preprocess_data(file_path)\n        column_mapping = infer_columns(data)\n        \n        if 'date' not in column_mapping:\n            data['date'] = pd.date_range(start='1/1/2020', periods=len(data), freq='D')\n        \n        if 'value' not in column_mapping:\n            data['value'] = data.select_dtypes(include=['float64', 'int64']).iloc[:, 0]\n        \n        if 'category' not in column_mapping:\n            data['category'] = 'default_category'\n        \n        data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\n    else:\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:27:51.241362Z","iopub.execute_input":"2025-01-03T21:27:51.241650Z","iopub.status.idle":"2025-01-03T21:27:56.280124Z","shell.execute_reply.started":"2025-01-03T21:27:51.241629Z","shell.execute_reply":"2025-01-03T21:27:56.279423Z"}},"outputs":[{"name":"stdout","text":"Loading and preprocessing data...\nLoading data from /kaggle/input/model-dataset-new-1/2017.csv\nData loaded successfully\nData preprocessing completed\nLoaded Data:    Country  Happiness.Rank  Happiness.Score  Whisker.high  Whisker.low  \\\n0      NaN       -1.720912         1.935996      1.921308     1.948466   \n1      NaN       -1.698563         1.922693      1.909902     1.933322   \n2      NaN       -1.676213         1.906730      1.946050     1.866469   \n3      NaN       -1.653864         1.897861      1.892003     1.901741   \n4      NaN       -1.631514         1.875689      1.861301     1.887924   \n\n   Economy..GDP.per.Capita.    Family  Health..Life.Expectancy.   Freedom  \\\n0                  1.506188  1.203577                  1.038167  1.515836   \n1                  1.186518  1.265036                  1.020812  1.452859   \n2                  1.182345  1.472669                  1.194259  1.460590   \n3                  1.383442  1.145561                  1.298272  1.413155   \n4                  1.093985  1.227057                  1.091026  1.398978   \n\n   Generosity  Trust..Government.Corruption.  Dystopia.Residual       date  \\\n0    0.856964                       1.903084           0.856296 2020-01-01   \n1    0.806856                       2.739998           0.929891 2020-01-02   \n2    1.702013                       0.300066           0.947964 2020-01-03   \n3    0.325028                       2.406809           0.855673 2020-01-04   \n4   -0.010426                       2.560800           1.163581 2020-01-05   \n\n   value          category  \n0      1  default_category  \n1      1  default_category  \n2      1  default_category  \n3      1  default_category  \n4      1  default_category  \nPerforming EDA...\nEDA Summary: {'shape': (155, 15), 'columns': ['Country', 'Happiness.Rank', 'Happiness.Score', 'Whisker.high', 'Whisker.low', 'Economy..GDP.per.Capita.', 'Family', 'Health..Life.Expectancy.', 'Freedom', 'Generosity', 'Trust..Government.Corruption.', 'Dystopia.Residual', 'date', 'value', 'category'], 'dtypes': [dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('<M8[ns]'), dtype('int64'), dtype('O')], 'null_counts': [155, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'describe': {'Country': {'count': 0.0, 'mean': nan, 'min': nan, '25%': nan, '50%': nan, '75%': nan, 'max': nan, 'std': nan}, 'Happiness.Rank': {'count': 155.0, 'mean': 9.168293364646454e-17, 'min': -1.7209121016305455, '25%': -0.8604560508152728, '50%': 0.0, '75%': 0.8604560508152728, 'max': 1.7209121016305455, 'std': 1.0032414995869672}, 'Happiness.Score': {'count': 155.0, 'mean': -2.7504880093939363e-16, 'min': -2.3599486914836305, '25%': -0.7525168929376604, '50%': -0.06653175762901539, '75%': 0.6629099098005016, 'max': 1.9359960228066444, 'std': 1.0032414995869672}, 'Whisker.high': {'count': 155.0, 'mean': 0.0, 'min': -2.3207258209501203, '25%': -0.7571377687765355, '50%': -0.07381086112416306, '75%': 0.6657597180905691, 'max': 1.9460497757443664, 'std': 1.003241499586967}, 'Whisker.low': {'count': 155.0, 'mean': 1.8336586729292908e-16, 'min': -2.395973777316477, '25%': -0.7716943477698013, '50%': -0.05481444500895716, '75%': 0.6578411083568523, 'max': 1.9484656100464395, 'std': 1.0032414995869672}, 'Economy..GDP.per.Capita.': {'count': 155.0, 'mean': -2.7504880093939363e-16, 'min': -2.347735936025894, '25%': -0.766147045844179, '50%': 0.1903992124371968, '75%': 0.7946657093368048, 'max': 2.1124881365135737, 'std': 1.0032414995869672}, 'Family': {'count': 155.0, 'mean': 3.6673173458585816e-16, 'min': -4.152125147537923, '25%': -0.5108106572540043, '50%': 0.22707625444875706, '75%': 0.7872533919312468, 'max': 1.4726687710486066, 'std': 1.0032414995869672}, 'Health..Life.Expectancy.': {'count': 155.0, 'mean': -2.2920733411616134e-16, 'min': -2.333157491013361, '25%': -0.767961612320804, '50%': 0.23148207189499787, '75%': 0.7264573385393689, 'max': 1.6848933474917969, 'std': 1.0032414995869672}, 'Freedom': {'count': 155.0, 'mean': 2.7504880093939363e-16, 'min': -2.7341228676716707, '25%': -0.7030093901303387, '50%': 0.19174504065498724, '75%': 0.7208447679883663, 'max': 1.6685055038393883, 'std': 1.0032414995869672}, 'Generosity': {'count': 155.0, 'mean': 1.2033385041098472e-16, 'min': -1.8376842724585936, '25%': -0.6905906988953184, '50%': -0.11422081917396318, '75%': 0.5722496574671866, 'max': 4.400552464845014, 'std': 1.0032414995869672}, 'Trust..Government.Corruption.': {'count': 155.0, 'mean': -9.168293364646454e-17, 'min': -1.2150164750834966, '25%': -0.6498387542022509, '50%': -0.32835288351226516, '75%': 0.2977939009267312, 'max': 3.367022164395706, 'std': 1.003241499586967}, 'Dystopia.Residual': {'count': 155.0, 'mean': 1.3752440046969682e-16, 'min': -2.954025697209275, '25%': -0.5195420348595526, '50%': -0.03476633152614659, '75%': 0.5907071746651429, 'max': 2.542564864159499, 'std': 1.0032414995869672}, 'date': {'count': 155, 'mean': Timestamp('2020-03-18 00:00:00'), 'min': Timestamp('2020-01-01 00:00:00'), '25%': Timestamp('2020-02-08 12:00:00'), '50%': Timestamp('2020-03-18 00:00:00'), '75%': Timestamp('2020-04-25 12:00:00'), 'max': Timestamp('2020-06-03 00:00:00'), 'std': nan}, 'value': {'count': 155.0, 'mean': 1.0, 'min': 1.0, '25%': 1.0, '50%': 1.0, '75%': 1.0, 'max': 1.0, 'std': 0.0}}}\nAnalyzing the user's prompt...\nAnalyzing prompt for insights\nNo insights could be extracted from the provided prompt. Using default insights.\nInsights extracted: ['trend', 'comparison']\nExtracted insights: ['trend', 'comparison']\nGenerating narration...\nCreating the infographic video...\nChecking data columns for required visualizations\nData columns: ['Country', 'Happiness.Rank', 'Happiness.Score', 'Whisker.high', 'Whisker.low', 'Economy..GDP.per.Capita.', 'Family', 'Health..Life.Expectancy.', 'Freedom', 'Generosity', 'Trust..Government.Corruption.', 'Dystopia.Residual', 'date', 'value', 'category']\nColumn mapping: {'category': 'category', 'value': 'value', 'date': 'date', 'x': 'Health..Life.Expectancy.', 'y': 'Country'}\nPipeline completed successfully in 3.89 seconds\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"# will work tommorow","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}