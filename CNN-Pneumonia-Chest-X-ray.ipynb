{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We are Performing and Rough Analysis On the Chest Classification X-rays using an Custom Build CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, InputLayer, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.metrics import AUC\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting an Random seed class or base for the Model Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set a seed value\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "\n",
    "#  TensorFlow's random\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 5. For layers that introduce randomness like dropout, make sure to set seed values \n",
    "#model.add(Dropout(0.25, seed=seed_value))\n",
    "\n",
    "# #6 Configure a new global `tensorflow` session\n",
    "# session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches of image data (train, validation, and test) with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '\\\\Users\\\\hellojenny\\\\Metis\\\\Metis-Bootcamp\\\\Projects/Project 5 - Image Prediction using CNN/chest_xray/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m val_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m) \n\u001b[0;32m     20\u001b[0m test_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m) \n\u001b[1;32m---> 23\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyper_dimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyper_dimension\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhyper_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhyper_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m val_generator \u001b[38;5;241m=\u001b[39m val_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(directory \u001b[38;5;241m=\u001b[39m val_path, \n\u001b[0;32m     30\u001b[0m                                                  target_size \u001b[38;5;241m=\u001b[39m (hyper_dimension, hyper_dimension),\n\u001b[0;32m     31\u001b[0m                                                  batch_size \u001b[38;5;241m=\u001b[39m hyper_batch_size, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m                                                  shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     35\u001b[0m                                                  seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     36\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(directory \u001b[38;5;241m=\u001b[39m test_path, \n\u001b[0;32m     37\u001b[0m                                                  target_size \u001b[38;5;241m=\u001b[39m (hyper_dimension, hyper_dimension),\n\u001b[0;32m     38\u001b[0m                                                  batch_size \u001b[38;5;241m=\u001b[39m hyper_batch_size, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m                                                  shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     42\u001b[0m                                                  seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\preprocessing\\image.py:1648\u001b[0m, in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '\\\\Users\\\\hellojenny\\\\Metis\\\\Metis-Bootcamp\\\\Projects/Project 5 - Image Prediction using CNN/chest_xray/train/'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ## Set file paths to image files\n",
    "# project_path = \"\\\\Users\\\\hellojenny\\\\Metis\\\\Metis-Bootcamp\\\\Projects/Project 5 - Image Prediction using CNN\"\n",
    "# train_path = project_path + \"/chest_xray/train/\"\n",
    "# val_path = project_path + \"/chest_xray/val/\"\n",
    "# test_path = project_path + \"/chest_xray/test/\"\n",
    "\n",
    "# ## Set up hyperparameters that will be used later\n",
    "# hyper_dimension = 64\n",
    "# hyper_batch_size = 128\n",
    "# hyper_epochs = 100\n",
    "# hyper_channels = 1\n",
    "# hyper_mode = 'grayscale'\n",
    "\n",
    "# ## Generate batches of image data (train, validation, and test) with data augmentation\n",
    "# train_datagen = ImageDataGenerator(rescale=1.0/255.0, \n",
    "#                                    shear_range = 0.2,\n",
    "#                                    zoom_range = 0.2, \n",
    "#                                    horizontal_flip = True)\n",
    "# val_datagen = ImageDataGenerator(rescale=1.0/255.0) \n",
    "# test_datagen = ImageDataGenerator(rescale=1.0/255.0) \n",
    "\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(directory = train_path, \n",
    "#                                                     target_size = (hyper_dimension, hyper_dimension),\n",
    "#                                                     batch_size = hyper_batch_size, \n",
    "#                                                     color_mode = hyper_mode,\n",
    "#                                                     class_mode = 'binary', \n",
    "#                                                     seed = 42)\n",
    "# val_generator = val_datagen.flow_from_directory(directory = val_path, \n",
    "#                                                  target_size = (hyper_dimension, hyper_dimension),\n",
    "#                                                  batch_size = hyper_batch_size, \n",
    "#                                                  class_mode = 'binary',\n",
    "#                                                  color_mode = hyper_mode,\n",
    "#                                                  shuffle=False,\n",
    "#                                                  seed = 42)\n",
    "# test_generator = test_datagen.flow_from_directory(directory = test_path, \n",
    "#                                                  target_size = (hyper_dimension, hyper_dimension),\n",
    "#                                                  batch_size = hyper_batch_size, \n",
    "#                                                  class_mode = 'binary',\n",
    "#                                                  color_mode = hyper_mode,\n",
    "#                                                  shuffle=False,\n",
    "#                                                  seed = 42)\n",
    "\n",
    "# test_generator.reset()\n",
    "\n",
    "\n",
    "# Some issues with this code the dataset i think the notebook needds to be handled on the kaggle platform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
