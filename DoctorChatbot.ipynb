{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f91bed798bb04b62adc75739f5445d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0607f32e121847c683ca0dd44c4c3092",
              "IPY_MODEL_fec91c72f65042d8aab10b44bbdd9192",
              "IPY_MODEL_a64a88fe064a4d53b424c310b85d4a4f"
            ],
            "layout": "IPY_MODEL_04caa8a1d3b24bffa46271d44fa9616b"
          }
        },
        "0607f32e121847c683ca0dd44c4c3092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9b731cd145a41f3a258b9a01e4624ee",
            "placeholder": "​",
            "style": "IPY_MODEL_0ac54f58373d4077b8fc0ede3a6ff07d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fec91c72f65042d8aab10b44bbdd9192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee89c9b4686c4c949d4f5292fc0e3217",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ca4f9e4f35747bc9ab2074d4aed8f0e",
            "value": 2
          }
        },
        "a64a88fe064a4d53b424c310b85d4a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a6ad24847884f74923c167d718d023a",
            "placeholder": "​",
            "style": "IPY_MODEL_33386b7830e746049823ab7c9749b4fe",
            "value": " 2/2 [02:46&lt;00:00, 166.69s/it]"
          }
        },
        "04caa8a1d3b24bffa46271d44fa9616b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b731cd145a41f3a258b9a01e4624ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac54f58373d4077b8fc0ede3a6ff07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee89c9b4686c4c949d4f5292fc0e3217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ca4f9e4f35747bc9ab2074d4aed8f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a6ad24847884f74923c167d718d023a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33386b7830e746049823ab7c9749b4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blacksujit/Deep-Learning-Specialization-Repo/blob/main/DoctorChatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio faiss-cpu PyPDF2 openai==0.28 tiktoken -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdoVHWQCVZZR",
        "outputId": "36fc92d5-fae6-443f-ea9d-30119bc2078c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.44.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.5)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.114.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.6)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.6.5)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.34)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.120)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.5.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio) (0.38.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.3)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOl01myFT2Yb"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "import faiss\n",
        "import numpy as np\n",
        "import requests\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI ve diğer API anahtarlarını ayarlayın\n",
        "openai_api_key = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"  # OpenAI API anahtarınızı buraya ekleyin\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "weather_api_key = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"  # OpenWeatherMap API anahtarınızı buraya ekleyin\n",
        "exchange_api_key = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"  # Exchangeratesapi.io API anahtarınızı buraya ekleyin\n"
      ],
      "metadata": {
        "id": "IHBF4TE3VcTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF dosyalarının yolları\n",
        "pdf_paths = ['/content/Current Essentials of Medicine.pdf'\n",
        "]\n",
        "\n",
        "# FAISS indeksi ve belgeler için global değişkenler\n",
        "vector_index = None\n",
        "documents = []\n",
        "chat_history = []"
      ],
      "metadata": {
        "id": "PA6W8LHvUg-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF'leri okuma ve indeksleme fonksiyonu\n",
        "def index_pdfs():\n",
        "    global vector_index, documents\n",
        "\n",
        "    for pdf_path in pdf_paths:\n",
        "        pdf_reader = PdfReader(pdf_path)\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text\n",
        "        documents.append(text)\n",
        "\n",
        "    combined_text = \" \".join(documents)\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    texts = text_splitter.split_text(combined_text)\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "    vectors = embeddings.embed_documents(texts)\n",
        "\n",
        "    vector_array = np.array(vectors)\n",
        "\n",
        "    index = faiss.IndexFlatL2(vector_array.shape[1])\n",
        "    index.add(vector_array)\n",
        "\n",
        "    vector_index = index\n",
        "\n",
        "    print(\"Bilgi tabanı başarıyla oluşturuldu!\")\n",
        "\n",
        "index_pdfs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkqKeMEgUhBm",
        "outputId": "db6c37ca-afcd-4763-a224-44554932ecb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-b3abdacc56b4>:19: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bilgi tabanı başarıyla oluşturuldu!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hava durumu verilerini çekmek için fonksiyon\n",
        "def fetch_weather(location):\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={weather_api_key}&units=metric&lang=tr\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        temp = data['main']['temp']\n",
        "        weather_description = data['weather'][0]['description']\n",
        "        return f\"{location} için anlık hava durumu: {temp}°C ve {weather_description}.\"\n",
        "    else:\n",
        "        return \"Hava durumu bilgilerini alamadım. Lütfen konumu kontrol edip tekrar deneyin.\"\n"
      ],
      "metadata": {
        "id": "RIw1JBFuUhDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Döviz kuru verilerini çekmek ve döviz dönüşümü yapmak için fonksiyon\n",
        "def fetch_exchange_rate(base_currency, target_currency, amount=1):\n",
        "    url = f\"https://api.exchangeratesapi.io/v1/latest?access_key={exchange_api_key}&format=1\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    rates = data.get('rates', {})\n",
        "    if target_currency in rates:\n",
        "        rate = rates[target_currency]\n",
        "        converted_amount = float(amount) * rate\n",
        "        return f\"{amount} {base_currency} = {converted_amount:.2f} {target_currency}.\"\n",
        "    else:\n",
        "        return f\"{target_currency} için döviz kuru bilgisi bulunamadı.\"\n"
      ],
      "metadata": {
        "id": "4IL7v9QdUhGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_chat_history(chat_history):\n",
        "    formatted_history = \"\"\n",
        "    for entry in chat_history:\n",
        "        if entry[\"role\"] == \"user\":\n",
        "            formatted_history += f\"<div class='chat-bubble user'>{entry['content']}</div>\"\n",
        "        else:\n",
        "            formatted_history += f\"<div class='chat-bubble assistant'>{entry['content']}</div>\"\n",
        "\n",
        "    return formatted_history"
      ],
      "metadata": {
        "id": "-5uDkSjnUhLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT-4 Yanıtını oluşturmak için fonksiyon (function calling ile)\n",
        "def generate_gpt4_response(prompt_input):\n",
        "    global vector_index, documents, chat_history\n",
        "    openai.api_key = openai_api_key\n",
        "\n",
        "    functions = [\n",
        "        {\n",
        "            \"name\": \"fetch_weather\",\n",
        "            \"description\": \"Belirli bir konum için hava durumu bilgisini alır.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Hava durumu almak istediğiniz konumun adı\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"fetch_exchange_rate\",\n",
        "            \"description\": \"Belirli iki para birimi arasındaki döviz kuru bilgisini alır ve isteğe bağlı olarak belirli bir miktar için dönüştürme yapar.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"base_currency\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Döviz kurunu almak istediğiniz temel para birimi, varsayılan olarak EUR'dir.\"\n",
        "                    },\n",
        "                    \"target_currency\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Döviz kurunu almak istediğiniz hedef para biriminin ISO 4217 kodu (örneğin: TRY)\"\n",
        "                    },\n",
        "                    \"amount\": {\n",
        "                        \"type\": \"number\",\n",
        "                        \"description\": \"Dönüştürmek istediğiniz miktar (varsayılan olarak 1).\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"base_currency\", \"target_currency\", \"amount\"],\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # OpenAI API çağrısı (function calling ile)\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model='gpt-4o-mini',\n",
        "        messages=[\n",
        "            {\"role\": \"system\",\n",
        "             \"content\": \"Sen tıp bilgileri ile donatılmış bir asistansın ve görevin tıbbi konulardaki sorulara cevap vermektir.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt_input}\n",
        "        ],\n",
        "        functions=functions,\n",
        "        function_call=\"auto\",  # Modelin fonksiyon çağrısına karar vermesine izin ver\n",
        "        temperature=0.5,\n",
        "        max_tokens=512\n",
        "    )\n",
        "\n",
        "    # Sohbet geçmişini güncelle\n",
        "    chat_history.append({\"role\": \"user\", \"content\": prompt_input})\n",
        "\n",
        "    # Bir fonksiyon çağrısı istenip istenmediğini kontrol et\n",
        "    if 'choices' in response and response['choices'][0]['finish_reason'] == 'function_call':\n",
        "        function_call_info = response['choices'][0]['message']['function_call']\n",
        "        function_name = function_call_info['name']\n",
        "        arguments = json.loads(function_call_info['arguments'])\n",
        "\n",
        "        if function_name == 'fetch_weather':\n",
        "            location = arguments['location']\n",
        "            weather_response = fetch_weather(location)\n",
        "            chat_history.append({\"role\": \"assistant\", \"content\": weather_response})\n",
        "            return format_chat_history(chat_history)\n",
        "        elif function_name == 'fetch_exchange_rate':\n",
        "            base_currency = arguments['base_currency']\n",
        "            target_currency = arguments['target_currency']\n",
        "            amount = arguments.get('amount', 1)\n",
        "            exchange_rate_response = fetch_exchange_rate(base_currency, target_currency, amount)\n",
        "            chat_history.append({\"role\": \"assistant\", \"content\": exchange_rate_response})\n",
        "            return format_chat_history(chat_history)\n",
        "\n",
        "    # Asistanın yanıtını al\n",
        "    assistant_response = response['choices'][0]['message']['content'].strip()\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "    return format_chat_history(chat_history)"
      ],
      "metadata": {
        "id": "k72356afUhIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    # CSS ile kaydırma özelliği ve stil düzenlemeleri\n",
        "    custom_css = \"\"\"\n",
        "    /* Chat balonları için stil */\n",
        "    .chat-bubble {\n",
        "        padding: 10px;\n",
        "        border-radius: 10px;\n",
        "        margin-bottom: 10px;\n",
        "        max-width: 60%;\n",
        "        word-wrap: break-word;\n",
        "    }\n",
        "\n",
        "    .user {\n",
        "        background-color: #d1e7dd;\n",
        "        text-align: right;\n",
        "        margin-left: auto;\n",
        "    }\n",
        "\n",
        "    .assistant {\n",
        "        background-color: #f8d7da;\n",
        "        text-align: left;\n",
        "        margin-right: auto;\n",
        "    }\n",
        "\n",
        "    /* Kaydırılabilir sohbet kutusu */\n",
        "    #output-box {\n",
        "        height: 400px;  /* Sabit yükseklik */\n",
        "        width: 100%;\n",
        "        overflow-y: scroll !important;  /* Kaydırmayı gizle ama JS ile açacağız */\n",
        "        padding: 10px;\n",
        "        border: 1px solid #ccc;\n",
        "        border-radius: 10px;\n",
        "        background-color: #f8f9fa;\n",
        "        margin-bottom: 20px;\n",
        "    }\n",
        "\n",
        "    /* Giriş kutusu */\n",
        "    #input-box {\n",
        "        height: 150px;\n",
        "        width: 100%;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    output_textbox = gr.HTML(label=\"Yanıt\", elem_id=\"output-box\")  # HTML bileşeni ile sohbeti gösteriyoruz\n",
        "    input_textbox = gr.Textbox(label=\"Sorunuzu girin\", lines=4, elem_id=\"input-box\")  # Giriş alanı\n",
        "\n",
        "    # Sorgu gönderildiğinde çalıştırılacak fonksiyon\n",
        "    def on_submit(prompt_input):\n",
        "        response = generate_gpt4_response(prompt_input)\n",
        "        return response, \"\"  # Giriş kutusunu temizle\n",
        "\n",
        "    # Sohbeti temizlemek için fonksiyon\n",
        "    def clear_chat():\n",
        "        global chat_history\n",
        "        chat_history.clear()\n",
        "        return \"\", \"\"  # Hem giriş kutusunu hem de sohbeti temizle\n",
        "\n",
        "    # Giriş kutusuna \"Enter\" basıldığında çalıştırılan fonksiyon\n",
        "    input_textbox.submit(on_submit, inputs=input_textbox, outputs=[output_textbox, input_textbox])\n",
        "\n",
        "    # Mesaj gönderme ve sohbeti temizleme butonları\n",
        "    submit_btn = gr.Button(\"Gönder\")\n",
        "    clear_btn = gr.Button(\"Chat'i Temizle\")\n",
        "\n",
        "    submit_btn.click(on_submit, inputs=input_textbox, outputs=[output_textbox, input_textbox])\n",
        "    clear_btn.click(clear_chat, outputs=[output_textbox, input_textbox])\n",
        "\n",
        "    demo.css = custom_css\n",
        "    demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "xNYH5O4hUhV1",
        "outputId": "80218d42-6523-456b-fc7b-d3ee8f6c2a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://1046f76164fb165e08.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1046f76164fb165e08.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://b162ad70725dccd76c.gradio.live\n",
            "Killing tunnel 127.0.0.1:7861 <> https://2eae138fb007aae19d.gradio.live\n",
            "Killing tunnel 127.0.0.1:7862 <> https://1dcffbd5ed4db3ce8d.gradio.live\n",
            "Killing tunnel 127.0.0.1:7863 <> https://c9b054571b98902445.gradio.live\n",
            "Killing tunnel 127.0.0.1:7864 <> https://6311d0f05878886aba.gradio.live\n",
            "Killing tunnel 127.0.0.1:7865 <> https://44bc8391d8b84b0e1d.gradio.live\n",
            "Killing tunnel 127.0.0.1:7866 <> https://1046f76164fb165e08.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio==3.50.2\n",
        "!pip install transformers==4.37.0\n",
        "!pip install torch==2.1.2"
      ],
      "metadata": {
        "id": "HbHxZ2VzVKkb",
        "outputId": "3d80882b-520f-4d33-b74b-6dbc0e906b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio==3.50.2\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.2)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (5.5.0)\n",
            "Collecting fastapi (from gradio==3.50.2)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==3.50.2)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50.2)\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.31.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio==3.50.2)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (3.10.0)\n",
            "Collecting numpy~=1.0 (from gradio==3.50.2)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.2.2)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio==3.50.2)\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.11.4)\n",
            "Collecting pydub (from gradio==3.50.2)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart (from gradio==3.50.2)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (6.0.2)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.32.3)\n",
            "Collecting semantic-version~=2.0 (from gradio==3.50.2)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.50.2)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2)\n",
            "  Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==0.6.1->gradio==3.50.2) (2025.3.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (1.38.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (3.18.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (2025.4.26)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (0.16.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi->gradio==3.50.2)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.50.2) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.50.2) (1.0.9)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.50.2) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->gradio==3.50.2) (1.3.1)\n",
            "Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, semantic-version, python-multipart, pillow, numpy, markupsafe, ffmpy, aiofiles, starlette, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.7.2 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\n",
            "google-genai 1.14.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-3.50.2 gradio-client-0.6.1 markupsafe-2.1.5 numpy-1.26.4 pillow-10.4.0 pydub-0.25.1 python-multipart-0.0.20 semantic-version-2.10.0 starlette-0.46.2 uvicorn-0.34.2 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "1aa62a75c8834bbab53879aeb8ad6e82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.37.0\n",
            "  Downloading transformers-4.37.0-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (0.31.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.0)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.0) (2025.4.26)\n",
            "Downloading transformers-4.37.0-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h^C\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
        "import torch\n",
        "from PIL import Image\n",
        "import logging\n",
        "from typing import Optional, Tuple, List, Dict\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class MedicalImageAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.image_processor = None\n",
        "        self.image_model = None\n",
        "        self.nlp_processor = None\n",
        "        self.load_models()\n",
        "\n",
        "    def load_models(self):\n",
        "        \"\"\"Load both image and NLP models\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Loading BLIP-2 model for image analysis...\")\n",
        "            self.image_processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
        "            self.image_model = Blip2ForConditionalGeneration.from_pretrained(\n",
        "                \"Salesforce/blip2-opt-2.7b\",\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\"\n",
        "            )\n",
        "\n",
        "            logger.info(\"Loading NLP models...\")\n",
        "            self.nlp_processor = pipeline(\n",
        "                \"text-generation\",\n",
        "                model=\"stanford-crfm/BioMedLM\",\n",
        "                device=self.device\n",
        "            )\n",
        "\n",
        "            logger.info(\"All models loaded successfully\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Model loading failed: {e}\")\n",
        "            raise RuntimeError(\"Failed to initialize models. Please check logs.\")\n",
        "\n",
        "    def analyze_image(self, image: Image.Image, clinical_context: str = \"\") -> Dict:\n",
        "        \"\"\"Analyze medical image with optional clinical context\"\"\"\n",
        "        try:\n",
        "            if not image:\n",
        "                raise ValueError(\"No image provided\")\n",
        "\n",
        "            # Generate radiology findings\n",
        "            prompt = self._build_radiology_prompt(clinical_context)\n",
        "            inputs = self.image_processor(image, text=prompt, return_tensors=\"pt\").to(self.device, torch.float16)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.image_model.generate(**inputs, max_new_tokens=300)\n",
        "\n",
        "            findings = self.image_processor.decode(outputs[0], skip_special_tokens=True)\n",
        "            findings = findings.replace(prompt, \"\").strip()\n",
        "\n",
        "            # Generate differential diagnosis\n",
        "            dd_prompt = f\"As a radiologist, suggest differential diagnoses for these findings:\\n{findings}\\n\\nDifferential Diagnoses:\"\n",
        "            dd_response = self.nlp_processor(\n",
        "                dd_prompt,\n",
        "                max_new_tokens=150,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "            differentials = dd_response[0][\"generated_text\"].replace(dd_prompt, \"\").strip()\n",
        "\n",
        "            return {\n",
        "                \"findings\": findings,\n",
        "                \"differentials\": differentials,\n",
        "                \"recommendations\": self._generate_recommendations(findings)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Analysis error: {e}\")\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def _build_radiology_prompt(self, clinical_context: str) -> str:\n",
        "        \"\"\"Build structured radiology prompt\"\"\"\n",
        "        return (\n",
        "            \"As a board-certified radiologist, carefully analyze this medical image. \"\n",
        "            f\"Clinical context: {clinical_context if clinical_context else 'Not provided'}. \"\n",
        "            \"Provide a professional interpretation noting:\\n\"\n",
        "            \"1. Anatomical structures visualized\\n\"\n",
        "            \"2. Abnormal findings\\n\"\n",
        "            \"3. Technical quality assessment\\n\"\n",
        "            \"4. Comparison to prior if available\\n\\n\"\n",
        "            \"Radiological Interpretation:\"\n",
        "        )\n",
        "\n",
        "    def _generate_recommendations(self, findings: str) -> str:\n",
        "        \"\"\"Generate clinical recommendations based on findings\"\"\"\n",
        "        prompt = (\n",
        "            \"As a radiologist, provide clinical recommendations based on these findings:\\n\"\n",
        "            f\"{findings}\\n\\n\"\n",
        "            \"Recommendations:\"\n",
        "        )\n",
        "        response = self.nlp_processor(\n",
        "            prompt,\n",
        "            max_new_tokens=200,\n",
        "            temperature=0.5,\n",
        "            do_sample=True\n",
        "        )\n",
        "        return response[0][\"generated_text\"].replace(prompt, \"\").strip()\n",
        "\n",
        "# Initialize the analyzer\n",
        "analyzer = MedicalImageAnalyzer()\n",
        "\n",
        "def analyze_medical_image(image: Image.Image, clinical_context: str = \"\") -> Dict:\n",
        "    \"\"\"Wrapper function for Gradio interface\"\"\"\n",
        "    try:\n",
        "        if not image:\n",
        "            return \"⚠️ Please upload a medical image\"\n",
        "\n",
        "        results = analyzer.analyze_image(image, clinical_context)\n",
        "\n",
        "        if \"error\" in results:\n",
        "            return f\"❌ Error: {results['error']}\"\n",
        "\n",
        "        return (\n",
        "            f\"**Clinical Context**: {clinical_context if clinical_context else 'None provided'}\\n\\n\"\n",
        "            f\"**Radiological Findings**:\\n{results['findings']}\\n\\n\"\n",
        "            f\"**Differential Diagnoses**:\\n{results['differentials']}\\n\\n\"\n",
        "            f\"**Recommendations**:\\n{results['recommendations']}\\n\\n\"\n",
        "            \"Note: This AI analysis should be verified by a qualified radiologist.\"\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Processing error: {e}\")\n",
        "        return f\"❌ Processing error: {str(e)}\"\n",
        "\n",
        "# Gradio Interface\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"Medical Image Analysis\") as app:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🩺 Advanced Medical Image Analysis\n",
        "    *Upload diagnostic images for comprehensive radiological analysis*\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            image_input = gr.Image(\n",
        "                type=\"pil\",\n",
        "                label=\"Upload Medical Image\",\n",
        "                sources=[\"upload\", \"clipboard\"]\n",
        "            )\n",
        "            context_input = gr.Textbox(\n",
        "                label=\"Clinical Context (optional)\",\n",
        "                placeholder=\"e.g., 45yo male with chronic leg pain...\",\n",
        "                lines=3\n",
        "            )\n",
        "            analyze_btn = gr.Button(\"Analyze\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            report_output = gr.Markdown(\n",
        "                label=\"Radiology Report\",\n",
        "                value=\"Analysis report will appear here...\"\n",
        "            )\n",
        "\n",
        "    analyze_btn.click(\n",
        "        analyze_medical_image,\n",
        "        inputs=[image_input, context_input],\n",
        "        outputs=report_output\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        app.launch(server_name=\"0.0.0.0\", server_port=13)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Application failed: {e}\")"
      ],
      "metadata": {
        "id": "XdxM_G07VKmy",
        "outputId": "41c36fa2-08c3-40b4-e697-5eed0b7d9176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771,
          "referenced_widgets": [
            "f91bed798bb04b62adc75739f5445d26",
            "0607f32e121847c683ca0dd44c4c3092",
            "fec91c72f65042d8aab10b44bbdd9192",
            "a64a88fe064a4d53b424c310b85d4a4f",
            "04caa8a1d3b24bffa46271d44fa9616b",
            "e9b731cd145a41f3a258b9a01e4624ee",
            "0ac54f58373d4077b8fc0ede3a6ff07d",
            "ee89c9b4686c4c949d4f5292fc0e3217",
            "6ca4f9e4f35747bc9ab2074d4aed8f0e",
            "3a6ad24847884f74923c167d718d023a",
            "33386b7830e746049823ab7c9749b4fe"
          ]
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f91bed798bb04b62adc75739f5445d26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n",
            "Device set to use cpu\n",
            "<ipython-input-5-7db77c085ecf>:146: GradioUnusedKwargWarning: You have unused kwarg parameters in Image, please remove them: {'sources': ['upload', 'clipboard']}\n",
            "  image_input = gr.Image(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://9d34668a67e4df87c9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9d34668a67e4df87c9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the first model implementation and code implementation"
      ],
      "metadata": {
        "id": "gTICnappVKpn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}