{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10356362,"sourceType":"datasetVersion","datasetId":6413607}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:20:31.705632Z","iopub.execute_input":"2025-01-04T07:20:31.705925Z","iopub.status.idle":"2025-01-04T07:20:31.732801Z","shell.execute_reply.started":"2025-01-04T07:20:31.705895Z","shell.execute_reply":"2025-01-04T07:20:31.731899Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/model-dataset-new-1/2015.csv\n/kaggle/input/model-dataset-new-1/2017.csv\n/kaggle/input/model-dataset-new-1/2019.csv\n/kaggle/input/model-dataset-new-1/main_data.csv\n/kaggle/input/model-dataset-new-1/2018.csv\n/kaggle/input/model-dataset-new-1/2016.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install gtts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:42:39.520485Z","iopub.execute_input":"2025-01-04T07:42:39.520825Z","iopub.status.idle":"2025-01-04T07:42:44.487535Z","shell.execute_reply.started":"2025-01-04T07:42:39.520801Z","shell.execute_reply":"2025-01-04T07:42:44.486505Z"}},"outputs":[{"name":"stdout","text":"Collecting gtts\n  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\nRequirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\nDownloading gTTS-2.5.4-py3-none-any.whl (29 kB)\nInstalling collected packages: gtts\nSuccessfully installed gtts-2.5.4\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import pandas as pd\nimport logging\nfrom sklearn.preprocessing import StandardScaler\nfrom transformers import BartTokenizer, BartForConditionalGeneration\nimport logging\nimport re\nimport spacy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport random\nfrom moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\nimport os\nimport time\nimport torch\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport logging\nimport os\nfrom PIL import Image\nfrom moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\nimport numpy as np\nimport io\nimport pandas as pd\nimport time\nfrom matplotlib.animation import FuncAnimation\nfrom gtts import gTTS\nfrom transformers import BartTokenizer, BartForConditionalGeneration\nimport spacy\nimport re\nimport pandas as pd\nimport logging\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\nimport logging\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\nimport logging\nfrom sklearn.preprocessing import StandardScaler\nimport pickle\nfrom transformers import BartTokenizer, BartForConditionalGeneration\nimport spacy\nimport os\nimport logging\n\n\n# nlp = spacy.load(\"en_core_web_sm\")\n\n# Setting up logging\nlogging.basicConfig(level=logging.INFO)\n\n# # Load spaCy model for NER\n# nlp = spacy.load(\"en_core_web_sm\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:45:07.244729Z","iopub.execute_input":"2025-01-04T07:45:07.245050Z","iopub.status.idle":"2025-01-04T07:45:07.251833Z","shell.execute_reply.started":"2025-01-04T07:45:07.245025Z","shell.execute_reply":"2025-01-04T07:45:07.250993Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# load and Preprocess the Data ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:45:12.170026Z","iopub.execute_input":"2025-01-04T07:45:12.170349Z","iopub.status.idle":"2025-01-04T07:45:12.174102Z","shell.execute_reply.started":"2025-01-04T07:45:12.170323Z","shell.execute_reply":"2025-01-04T07:45:12.172981Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"def load_and_preprocess_data(file_path):\n    try:\n        logging.info(f\"Loading data from {file_path}\")\n        # Load data\n        if file_path.endswith('.csv'):\n            data = pd.read_csv(file_path)\n        elif file_path.endswith('.xlsx'):\n            data = pd.read_excel(file_path)\n        elif file_path.endswith('.txt'):\n            data = pd.read_csv(file_path, delimiter='\\t')\n        else:\n            raise ValueError(\"Unsupported file format.\")\n        \n        logging.info(\"Data loaded successfully\")\n        \n        # Detect and convert data types\n        for col in data.columns:\n            try:\n                data[col] = pd.to_numeric(data[col], errors='coerce')\n            except ValueError:\n                pass\n        \n        # Handle missing values\n        data.fillna(data.mean(), inplace=True)\n        \n        # Handle categorical data\n        categorical_cols = data.select_dtypes(include=['object']).columns\n        data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n        \n        # Normalize numeric data\n        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n        scaler = StandardScaler()\n        data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n        \n        logging.info(\"Data preprocessing completed\")\n        return data\n    except Exception as e:\n        logging.error(f\"Error loading and preprocessing data: {e}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:45:12.250736Z","iopub.execute_input":"2025-01-04T07:45:12.251052Z","iopub.status.idle":"2025-01-04T07:45:12.257660Z","shell.execute_reply.started":"2025-01-04T07:45:12.251028Z","shell.execute_reply":"2025-01-04T07:45:12.256655Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def perform_eda(data):\n    try:\n        eda_summary = {\n            \"shape\": data.shape,\n            \"columns\": data.columns.tolist(),\n            \"dtypes\": data.dtypes.tolist(),\n            \"null_counts\": data.isnull().sum().tolist(),\n            \"describe\": data.describe().to_dict()\n        }\n        return eda_summary\n    except Exception as e:\n        logging.error(f\"Error performing EDA: {e}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:45:12.940230Z","iopub.execute_input":"2025-01-04T07:45:12.940579Z","iopub.status.idle":"2025-01-04T07:45:12.945118Z","shell.execute_reply.started":"2025-01-04T07:45:12.940553Z","shell.execute_reply":"2025-01-04T07:45:12.944316Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def save_models(model_name=\"facebook/bart-large\", save_directory=\"models\"):\n    if not os.path.exists(save_directory):\n        os.makedirs(save_directory)\n    \n    # Load the tokenizer and model\n    tokenizer = BartTokenizer.from_pretrained(model_name)\n    model = BartForConditionalGeneration.from_pretrained(model_name)\n    \n    # Save the tokenizer and model as .pkl files\n    with open(os.path.join(save_directory, \"facebook_tokenizer.pkl\"), \"wb\") as f:\n        pickle.dump(tokenizer, f)\n    with open(os.path.join(save_directory, \"facebook_model.pkl\"), \"wb\") as f:\n        pickle.dump(model, f)\n    \n    # Load and save the spaCy model\n    nlp = spacy.load(\"en_core_web_sm\")\n    with open(os.path.join(save_directory, \"spacy_model.pkl\"), \"wb\") as f:\n        pickle.dump(nlp, f)\n    \n    logging.info(f\"Models saved to {save_directory}\")\n\n# Call this function once to save the models\nsave_models()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:45:15.030627Z","iopub.execute_input":"2025-01-04T07:45:15.030947Z","iopub.status.idle":"2025-01-04T07:45:21.023544Z","shell.execute_reply.started":"2025-01-04T07:45:15.030921Z","shell.execute_reply":"2025-01-04T07:45:21.022800Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"def load_models(model_directory=\"models\"):\n    # Load the tokenizer and model from the saved .pkl files\n    with open(os.path.join(model_directory, \"facebook_tokenizer.pkl\"), \"rb\") as f:\n        tokenizer = pickle.load(f)\n    with open(os.path.join(model_directory, \"facebook_model.pkl\"), \"rb\") as f:\n        model = pickle.load(f)\n    \n    # Load the spaCy model from the saved .pkl file\n    with open(os.path.join(model_directory, \"spacy_model.pkl\"), \"rb\") as f:\n        nlp = pickle.load(f)\n    \n    return tokenizer, model, nlp\n\n# Load the models\ntokenizer, model, nlp = load_models()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:45:23.785678Z","iopub.execute_input":"2025-01-04T07:45:23.786142Z","iopub.status.idle":"2025-01-04T07:45:25.107997Z","shell.execute_reply.started":"2025-01-04T07:45:23.786105Z","shell.execute_reply":"2025-01-04T07:45:25.107054Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def analyze_prompt_for_insights(prompt):\n    try:\n        # logging.info(\"Analyzing prompt for insights\")\n        # tokenizer = BartTokenizer.from_pretrained(model_name)\n        # model = BartForConditionalGeneration.from_pretrained(model_name)\n        \n        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n        input_ids = inputs.input_ids\n        attention_mask = inputs.attention_mask\n        \n        outputs = model.generate(\n            input_ids,\n            attention_mask=attention_mask,\n            max_length=200,\n            num_return_sequences=1,\n            temperature=0.7,\n            top_p=0.9,\n            top_k=50,\n            no_repeat_ngram_size=2,\n            pad_token_id=tokenizer.eos_token_id\n        )\n        \n        generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n        insights = extract_insights_from_text(generated_text)\n        \n        insights_list = [key for key, value in insights.items() if value]\n        if not insights_list:\n            raise ValueError(\"No insights could be extracted from the provided prompt.\")\n        \n        logging.info(f\"Insights extracted: {insights_list}\")\n        return insights_list\n    except Exception as e:\n        logging.error(f\"Error in analyzing prompt for insights: {e}\")\n        return []\n\ndef extract_insights_from_text(text):\n    possible_insights = [\"trend\", \"comparison\", \"distribution\", \"correlation\", \"pattern\", \"anomaly\", \"outlier\", \"relationship\", \"performance\", \"growth\"]\n    insights = {insight: False for insight in possible_insights}\n    text = text.lower()\n    \n    for insight in possible_insights:\n        if re.search(r'\\b' + re.escape(insight) + r'\\b', text):\n            insights[insight] = True\n    \n    doc = nlp(text)\n    entities = [(ent.text, ent.label_) for ent in doc.ents]\n    insights['entities'] = entities\n    \n    return insights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:48:47.526029Z","iopub.execute_input":"2025-01-04T07:48:47.526319Z","iopub.status.idle":"2025-01-04T07:48:47.533502Z","shell.execute_reply.started":"2025-01-04T07:48:47.526299Z","shell.execute_reply":"2025-01-04T07:48:47.532584Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"\ndef generate_animated_frames(data):\n    logging.info(\"Generating animated frames from data\")\n    frames = []\n    \n    # Generate a basic time series plot if a date column is present\n    date_column = None\n    for col in data.columns:\n        if 'date' in col.lower() or 'time' in col.lower():\n            date_column = col\n            break\n    \n    if date_column:\n        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n        if len(numeric_columns) > 0:\n            fig, ax = plt.subplots(figsize=(10, 6))\n            lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n            ax.set_xlim(data[date_column].min(), data[date_column].max())\n            ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n            ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n            ax.set_xlabel('Time')\n            ax.set_ylabel('Values')\n            ax.legend()\n\n            def update(frame):\n                for line, col in zip(lines, numeric_columns):\n                    line.set_data(data[date_column][:frame], data[col][:frame])\n                return lines\n\n            ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n            for i in range(len(data)):\n                update(i)\n                buf = io.BytesIO()\n                fig.savefig(buf, format='png')\n                buf.seek(0)\n                img = Image.open(buf)\n                frames.append(np.array(img))\n            plt.close(fig)\n    \n    # Generate an animated bar chart\n    if 'category' in data.columns and 'value' in data.columns:\n        fig, ax = plt.subplots(figsize=(10, 6))\n        categories = data['category'].unique()\n        bars = ax.bar(categories, np.zeros(len(categories)))\n        ax.set_ylim(0, data['value'].max())\n        ax.set_title('Animated Bar Chart')\n        ax.set_xlabel('Category')\n        ax.set_ylabel('Value')\n\n        def update_bar(frame):\n            for bar, category in zip(bars, categories):\n                bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n            return bars\n\n        ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n        for i in range(len(data)):\n            update_bar(i)\n            buf = io.BytesIO()\n            fig.savefig(buf, format='png')\n            buf.seek(0)\n            img = Image.open(buf)\n            frames.append(np.array(img))\n        plt.close(fig)\n    \n    # Generate an animated pie chart\n    if 'category' in data.columns and 'value' in data.columns:\n        fig, ax = plt.subplots(figsize=(10, 6))\n        def update_pie(frame):\n            ax.clear()\n            ax.pie(data['value'][:frame], labels=data['category'][:frame], autopct='%1.1f%%')\n            ax.set_title('Animated Pie Chart')\n\n        ani = FuncAnimation(fig, update_pie, frames=len(data), blit=True)\n        for i in range(len(data)):\n            update_pie(i)\n            buf = io.BytesIO()\n            fig.savefig(buf, format='png')\n            buf.seek(0)\n            img = Image.open(buf)\n            frames.append(np.array(img))\n        plt.close(fig)\n    \n    # Generate a correlation matrix plot\n    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n        corr_matrix = data.corr()\n        fig, ax = plt.subplots(figsize=(10, 6))\n        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n        ax.set_title('Correlation Matrix')\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(np.array(img))\n        plt.close(fig)\n    \n    # Generate distribution plots for numeric columns\n    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n    for col in numeric_columns:\n        fig, ax = plt.subplots(figsize=(8, 6))\n        sns.histplot(data[col], bins=10, kde=True, ax=ax)\n        ax.set_title(f\"Distribution of {col}\")\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png')\n        buf.seek(0)\n        img = Image.open(buf)\n        frames.append(np.array(img))\n        plt.close(fig)\n    \n    logging.info(f\"Generated {len(frames)} animated frames\")\n    return frames","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:48:48.997442Z","iopub.execute_input":"2025-01-04T07:48:48.997762Z","iopub.status.idle":"2025-01-04T07:48:49.012660Z","shell.execute_reply.started":"2025-01-04T07:48:48.997737Z","shell.execute_reply":"2025-01-04T07:48:49.011672Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"\ndef create_video_from_frames(frames, audio_file=None, video_file=\"final_production_model.mp4\"):\n    if not frames:\n        raise ValueError(\"No frames to create video from.\")\n    \n    logging.info(\"Creating video from frames\")\n    video_clips = []\n    for frame in frames:\n        img_clip = ImageSequenceClip([frame], fps=1)  # 1 frame per second\n        img_clip = img_clip.set_duration(2)  # Each frame lasts 2 seconds\n        video_clips.append(img_clip)\n    \n    video = concatenate_videoclips(video_clips, method=\"compose\")\n    \n    if audio_file and os.path.isfile(audio_file):\n        audio = AudioFileClip(audio_file)\n        video = video.set_audio(audio)\n    \n    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n    logging.info(f\"Video saved as {video_file}\")\n\ndef generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n    frames = generate_animated_frames(data)\n    if not frames:\n        raise ValueError(\"No frames generated from data.\")\n    \n    if os.path.exists(title_image):\n        title_image_clip = Image.open(title_image)\n        title_image_clip = title_image_clip.convert(\"RGBA\")\n        title_image_clip = np.array(title_image_clip)\n        frames.insert(0, title_image_clip)\n    \n    create_video_from_frames(frames, audio_file)\n    print(\"Video successfully generated!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:48:50.941646Z","iopub.execute_input":"2025-01-04T07:48:50.942059Z","iopub.status.idle":"2025-01-04T07:48:50.950834Z","shell.execute_reply.started":"2025-01-04T07:48:50.942028Z","shell.execute_reply":"2025-01-04T07:48:50.949891Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"def generate_narration(text, output_file=\"narration.mp3\"):\n    tts = gTTS(text=text, lang='en')\n    tts.save(output_file)\n    return output_file","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:48:53.140031Z","iopub.execute_input":"2025-01-04T07:48:53.140315Z","iopub.status.idle":"2025-01-04T07:48:53.144027Z","shell.execute_reply.started":"2025-01-04T07:48:53.140293Z","shell.execute_reply":"2025-01-04T07:48:53.143289Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n    try:\n        start_time = time.time()\n        \n        logging.info(\"Loading and preprocessing data...\")\n        data = load_and_preprocess_data(file_path)\n        logging.debug(f\"Loaded Data: {data.head()}\")\n        \n        logging.info(\"Performing EDA...\")\n        eda_summary = perform_eda(data)\n        logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n        logging.info(\"Analyzing the user's prompt...\")\n        insights = analyze_prompt_for_insights(prompt)\n        logging.debug(f\"Extracted insights: {insights}\")\n        \n        logging.info(\"Generating narration...\")\n        narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n        narration_file = generate_narration(narration_text)\n        \n        logging.info(\"Creating the infographic video...\")\n        generate_infographic_video(data, insights, audio_file=narration_file)\n        \n        end_time = time.time()\n        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n    except FileNotFoundError as fnf_error:\n        logging.error(f\"File not found: {fnf_error}\")\n        raise\n    except pd.errors.ParserError as parser_error:\n        logging.error(f\"Error parsing the file: {parser_error}\")\n        raise\n    except TypeError as type_error:\n        logging.error(f\"Type error: {type_error}\")\n        raise\n    except ValueError as value_error:\n        logging.error(f\"Value error: {value_error}\")\n        raise\n    except Exception as e:\n        logging.error(f\"An unexpected error occurred: {e}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:48:55.190782Z","iopub.execute_input":"2025-01-04T07:48:55.191094Z","iopub.status.idle":"2025-01-04T07:48:55.197334Z","shell.execute_reply.started":"2025-01-04T07:48:55.191070Z","shell.execute_reply":"2025-01-04T07:48:55.196331Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Example usage:\nfile_path = '/kaggle/input/model-dataset-new-1/2017.csv'\nprompt = \"compare the family and generaosity in an interactive video format\"\naudio_file = \"/kaggle/working/\"\ntitle_image = \"/kaggle/working/\"\n\nif not os.path.exists(file_path):\n    raise FileNotFoundError(f\"Data file not found: {file_path}\")\nif not os.path.exists(audio_file):\n    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\nif not os.path.exists(title_image):\n    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\ndata_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:48:56.580874Z","iopub.execute_input":"2025-01-04T07:48:56.581161Z","iopub.status.idle":"2025-01-04T07:49:18.809164Z","shell.execute_reply.started":"2025-01-04T07:48:56.581139Z","shell.execute_reply":"2025-01-04T07:49:18.808330Z"}},"outputs":[{"name":"stdout","text":"Moviepy - Building video final_production_model.mp4.\nMoviePy - Writing audio in final_production_modelTEMP_MPY_wvf_snd.mp3\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\nMoviepy - Writing video final_production_model.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready final_production_model.mp4\nVideo successfully generated!\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"#### DONE ✅","metadata":{}},{"cell_type":"markdown","source":"# OLD MODEL CODE IMPLEMENTATION","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import plotly.express as px\n# import pandas as pd\n# import logging\n\n# def generate_visualizations(data, insights):\n#     try:\n#         logging.info(\"Generating visualizations\")\n#         if data.empty:\n#             raise ValueError(\"Data is empty.\")\n#         if not insights:\n#             raise ValueError(\"No insights available to generate visualizations.\")\n        \n#         visuals = []\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n        \n#         if 'Date' in data.columns or 'Datetime' in data.columns:\n#             time_column = 'Date' if 'Date' in data.columns else 'Datetime'\n#             if numeric_columns.any():\n#                 fig = px.line(data, x=time_column, y=numeric_columns, title=f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#                 visuals.append(fig)\n        \n#         if len(numeric_columns) > 1:\n#             corr_matrix = data[numeric_columns].corr()\n#             fig = px.imshow(corr_matrix, text_auto=True, title='Correlation Matrix')\n#             visuals.append(fig)\n        \n#         for col in categorical_columns:\n#             fig = px.histogram(data, x=col, title=f\"Distribution of {col}\")\n#             visuals.append(fig)\n        \n#         if len(numeric_columns) > 1:\n#             fig = px.scatter_matrix(data, dimensions=numeric_columns, title='Pairwise Relationships')\n#             visuals.append(fig)\n        \n#         if not visuals:\n#             return None\n        \n#         logging.info(f\"Generated {len(visuals)} visualizations\")\n#         return visuals\n#     except Exception as e:\n#         logging.error(f\"Error generating visualizations: {e}\")\n#         raise\n\n# # # Example usage:\n# # file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# # data = pd.read_csv(file_path)\n# # insights = \"Sample insights based on the data\"\n# # visuals = generate_visualizations(data, insights)\n\n# # # To display the visualizations in a Jupyter notebook\n# # for fig in visuals:\n# #     fig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:42:00.636783Z","iopub.execute_input":"2025-01-04T07:42:00.637118Z","iopub.status.idle":"2025-01-04T07:42:00.641168Z","shell.execute_reply.started":"2025-01-04T07:42:00.637092Z","shell.execute_reply":"2025-01-04T07:42:00.640237Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import logging\n\n# def generate_default_frames(data):\n#     logging.info(\"Generating default frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             plt.figure(figsize=(10, 6))\n#             for col in numeric_columns:\n#                 plt.plot(data[date_column], data[col], label=col)\n#             plt.title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             plt.xlabel('Time')\n#             plt.ylabel('Values')\n#             plt.xticks(rotation=45)\n#             plt.legend()\n#             frames.append(plt)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         plt.figure(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n#         plt.title('Correlation Matrix')\n#         frames.append(plt)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         plt.figure(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True)\n#         plt.title(f\"Distribution of {col}\")\n#         frames.append(plt)\n    \n#     logging.info(f\"Generated {len(frames)} default frames\")\n#     return frames","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:42:07.251664Z","iopub.execute_input":"2025-01-04T07:42:07.251969Z","iopub.status.idle":"2025-01-04T07:42:07.255920Z","shell.execute_reply.started":"2025-01-04T07:42:07.251947Z","shell.execute_reply":"2025-01-04T07:42:07.254919Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# print(frames)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:32:14.492944Z","iopub.execute_input":"2025-01-03T13:32:14.493227Z","iopub.status.idle":"2025-01-03T13:32:14.497203Z","shell.execute_reply.started":"2025-01-03T13:32:14.493207Z","shell.execute_reply":"2025-01-03T13:32:14.496317Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n#     video = video_clips[0]\n#     for clip in video_clips[1:]:\n#         video = concatenate_videoclips([video, clip], method=\"compose\")\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:42:10.251091Z","iopub.execute_input":"2025-01-04T07:42:10.251413Z","iopub.status.idle":"2025-01-04T07:42:10.254902Z","shell.execute_reply.started":"2025-01-04T07:42:10.251390Z","shell.execute_reply":"2025-01-04T07:42:10.253932Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_default_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:42:13.860907Z","iopub.execute_input":"2025-01-04T07:42:13.861209Z","iopub.status.idle":"2025-01-04T07:42:13.865127Z","shell.execute_reply.started":"2025-01-04T07:42:13.861186Z","shell.execute_reply":"2025-01-04T07:42:13.864197Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\n# # # Predefined prompts for prompt engineering\n# # predefined_prompts = [\n# #     \"Analyze the sales trends over time and regional performance.\",\n# #     \"Identify key trends, comparisons, distributions, and correlations in the data.\",\n# #     \"Generate insights on the performance and growth of different regions.\",\n# #     \"Highlight any anomalies or outliers in the sales data.\",\n# #     \"Compare the sales performance across different product categories.\",\n# #     \"Analyze the correlation between sales and marketing spend.\",\n# #     \"Identify patterns in customer purchase behavior.\",\n# #     \"Generate insights on the distribution of sales across different regions.\",\n# #     \"Analyze the relationship between sales and customer demographics.\",\n# #     \"Identify key performance indicators for the sales team.\",\n# #     # Add more prompts as needed\n# # ]\n\n# # # Test the pipeline with predefined prompts\n# # for test_prompt in predefined_prompts:\n# #     try:\n# #         logging.info(f\"Testing with prompt: {test_prompt}\")\n# #         data_storytelling_pipeline(file_path, test_prompt, audio_file=audio_file)\n# #     except Exception as e:\n# #         logging.error(f\"Error with prompt '{test_prompt}': {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:42:53.306048Z","iopub.execute_input":"2025-01-03T12:42:53.306235Z","iopub.status.idle":"2025-01-03T12:42:53.322383Z","shell.execute_reply.started":"2025-01-03T12:42:53.306219Z","shell.execute_reply":"2025-01-03T12:42:53.321636Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n# import numpy as np\n\n# def generate_default_frames(data):\n#     logging.info(\"Generating default frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             plt.figure(figsize=(10, 6))\n#             for col in numeric_columns:\n#                 plt.plot(data[date_column], data[col], label=col)\n#             plt.title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             plt.xlabel('Time')\n#             plt.ylabel('Values')\n#             plt.xticks(rotation=45)\n#             plt.legend()\n#             frames.append(plt)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         plt.figure(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n#         plt.title('Correlation Matrix')\n#         frames.append(plt)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         plt.figure(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True)\n#         plt.title(f\"Distribution of {col}\")\n#         frames.append(plt)\n    \n#     logging.info(f\"Generated {len(frames)} default frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = [ImageSequenceClip([np.array(frame.canvas.buffer_rgba())], fps=24) for frame in frames]\n    \n#     video = video_clips[0]\n#     for clip in video_clips[1:]:\n#         video = concatenate_videoclips([video, clip], method=\"compose\")\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_default_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:42:53.323142Z","iopub.execute_input":"2025-01-03T12:42:53.323406Z","iopub.status.idle":"2025-01-03T12:42:53.339760Z","shell.execute_reply.started":"2025-01-03T12:42:53.323387Z","shell.execute_reply":"2025-01-03T12:42:53.338997Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# OLD MODEL CODE IMPLEMENTATION TILL HERE ","metadata":{}},{"cell_type":"markdown","source":"# WORKING CODE COMMENTED FOR REFERANCE ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n# import numpy as np\n# import io\n\n# def generate_default_frames(data):\n#     logging.info(\"Generating default frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             for col in numeric_columns:\n#                 ax.plot(data[date_column], data[col], label=col)\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n#             buf = io.BytesIO()\n#             fig.savefig(buf, format='png')\n#             buf.seek(0)\n#             img = Image.open(buf)\n#             frames.append(img)\n#             plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} default frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n#     video = video_clips[0]\n#     for clip in video_clips[1:]:\n#         video = concatenate_videoclips([video, clip], method=\"compose\")\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_default_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:51:53.678739Z","iopub.execute_input":"2025-01-04T07:51:53.679086Z","iopub.status.idle":"2025-01-04T07:51:53.684871Z","shell.execute_reply.started":"2025-01-04T07:51:53.679063Z","shell.execute_reply":"2025-01-04T07:51:53.683933Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n# import numpy as np\n# import io\n# from matplotlib.animation import FuncAnimation\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             for i in range(len(data)):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(img)\n#             plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n#     video = video_clips[0]\n#     for clip in video_clips[1:]:\n#         video = concatenate_videoclips([video, clip], method=\"compose\")\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:51:58.448794Z","iopub.execute_input":"2025-01-04T07:51:58.449144Z","iopub.status.idle":"2025-01-04T07:51:58.454598Z","shell.execute_reply.started":"2025-01-04T07:51:58.449116Z","shell.execute_reply":"2025-01-04T07:51:58.453381Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip\n# import numpy as np\n# import io\n# from matplotlib.animation import FuncAnimation\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             for i in range(len(data)):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(img)\n#             plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n#     # Add transitions between clips\n#     def add_transition(clip1, clip2, duration=1):\n#         return concatenate_videoclips([clip1.crossfadeout(duration), clip2.crossfadein(duration)], method=\"compose\")\n    \n#     video = video_clips[0]\n#     for clip in video_clips[1:]:\n#         video = add_transition(video, clip)\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     video = video.set_duration(max(60, video.duration))  # Ensure video is at least 60 seconds long\n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:52:01.358384Z","iopub.execute_input":"2025-01-04T07:52:01.358680Z","iopub.status.idle":"2025-01-04T07:52:01.363604Z","shell.execute_reply.started":"2025-01-04T07:52:01.358658Z","shell.execute_reply":"2025-01-04T07:52:01.362707Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n# import numpy as np\n# import io\n# from matplotlib.animation import FuncAnimation\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             for i in range(len(data)):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(img)\n#             plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n#     # Add transitions between clips\n#     def add_transition(clip1, clip2, duration=1):\n#         return concatenate_videoclips([clip1.crossfadeout(duration), clip2.crossfadein(duration)], method=\"compose\")\n    \n#     video = video_clips[0]\n#     for clip in video_clips[1:]:\n#         video = add_transition(video, clip)\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     # Add a title screen\n#     title = TextClip(\"Data Storytelling\", fontsize=70, color='white', bg_color='black', size=video.size)\n#     title = title.set_duration(3).fadein(1).fadeout(1)\n#     video = concatenate_videoclips([title, video])\n    \n#     video = video.set_duration(max(60, video.duration))  # Ensure video is at least 60 seconds long\n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.627049Z","iopub.execute_input":"2025-01-03T12:43:34.627343Z","iopub.status.idle":"2025-01-03T12:43:34.637150Z","shell.execute_reply.started":"2025-01-03T12:43:34.627315Z","shell.execute_reply":"2025-01-03T12:43:34.636476Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# !pip install imagemagick","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.637965Z","iopub.execute_input":"2025-01-03T12:43:34.638222Z","iopub.status.idle":"2025-01-03T12:43:34.656841Z","shell.execute_reply.started":"2025-01-03T12:43:34.638196Z","shell.execute_reply":"2025-01-03T12:43:34.656041Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n# import numpy as np\n# import io\n# from matplotlib.animation import FuncAnimation\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             for i in range(len(data)):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(img)\n#             plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n#     # Add transitions between clips\n#     def add_transition(clip1, clip2, duration=1):\n#         return concatenate_videoclips([clip1.crossfadeout(duration), clip2.crossfadein(duration)], method=\"compose\")\n    \n#     video = video_clips[0]\n#     for clip in video_clips[1:]:\n#         video = add_transition(video, clip)\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     # Add a title screen\n#     title = TextClip(\"Data Storytelling\", fontsize=70, color='white', bg_color='black', size=video.size)\n#     title = title.set_duration(3).fadein(1).fadeout(1)\n#     video = concatenate_videoclips([title, video])\n    \n#     video = video.set_duration(max(60, video.duration))  # Ensure video is at least 60 seconds long\n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.657548Z","iopub.execute_input":"2025-01-03T12:43:34.657780Z","iopub.status.idle":"2025-01-03T12:43:34.672309Z","shell.execute_reply.started":"2025-01-03T12:43:34.657748Z","shell.execute_reply":"2025-01-03T12:43:34.671394Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# import numpy as np\n# import io\n# from matplotlib.animation import FuncAnimation\n# import cv2\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             for i in range(len(data)):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(np.array(img))\n#             plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"new_final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     height, width, layers = frames[0].shape\n#     video = cv2.VideoWriter(video_file, cv2.VideoWriter_fourcc(*'mp4v'), 24, (width, height))\n    \n#     for frame in frames:\n#         video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n    \n#     video.release()\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.673142Z","iopub.execute_input":"2025-01-03T12:43:34.673471Z","iopub.status.idle":"2025-01-03T12:43:34.692178Z","shell.execute_reply.started":"2025-01-03T12:43:34.673441Z","shell.execute_reply":"2025-01-03T12:43:34.691140Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# import numpy as np\n# import io\n# from matplotlib.animation import FuncAnimation\n# import cv2\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             for i in range(len(data)):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(np.array(img))\n#             plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"second_final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     height, width, layers = frames[0].shape\n#     video = cv2.VideoWriter(video_file, cv2.VideoWriter_fourcc(*'mp4v'), 24, (width, height))\n    \n#     # Add a title screen\n#     title_screen = np.zeros((height, width, 3), dtype=np.uint8)\n#     title_screen.fill(0)  # Black background\n#     cv2.putText(title_screen, \"Data Storytelling\", (50, height // 2), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n#     for _ in range(72):  # 3 seconds at 24 fps\n#         video.write(title_screen)\n    \n#     for frame in frames:\n#         for _ in range(3):  # Repeat each frame to slow down the video\n#             video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n    \n#     # Ensure video is at least 60 seconds long\n#     while video.get(cv2.CAP_PROP_FRAME_COUNT) < 60 * 24:\n#         video.write(title_screen)\n    \n#     video.release()\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.692941Z","iopub.execute_input":"2025-01-03T12:43:34.693224Z","iopub.status.idle":"2025-01-03T12:43:34.704502Z","shell.execute_reply.started":"2025-01-03T12:43:34.693189Z","shell.execute_reply":"2025-01-03T12:43:34.703711Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# import numpy as np\n# import io\n# from matplotlib.animation import FuncAnimation\n# import cv2\n# import pandas as pd\n# import time\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data)//10, blit=True)\n#             for i in range(len(data)//10):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(np.array(img))\n#             plt.close(fig)\n    \n#     # Generate a moving bar chart\n#     if 'category' in data.columns and 'value' in data.columns:\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         categories = data['category'].unique()\n#         bars = ax.bar(categories, np.zeros(len(categories)))\n#         ax.set_ylim(0, data['value'].max())\n#         ax.set_title('Moving Bar Chart')\n#         ax.set_xlabel('Category')\n#         ax.set_ylabel('Value')\n\n#         def update_bar(frame):\n#             for bar, category in zip(bars, categories):\n#                 bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n#             return bars\n\n#         ani = FuncAnimation(fig, update_bar, frames=len(data)//10, blit=True)\n#         for i in range(len(data)//10):\n#             update_bar(i)\n#             buf = io.BytesIO()\n#             fig.savefig(buf, format='png')\n#             buf.seek(0)\n#             img = Image.open(buf)\n#             frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate a pairplot for numeric columns\n#     if len(numeric_columns) > 1:\n#         sns.pairplot(data[numeric_columns])\n#         plt.suptitle('Pairplot of Numeric Columns', y=1.02)\n#         buf = io.BytesIO()\n#         plt.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close()\n    \n#     # Generate a line plot for each numeric column\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         ax.plot(data.index, data[col])\n#         ax.set_title(f\"Line Plot of {col}\")\n#         ax.set_xlabel('Index')\n#         ax.set_ylabel(col)\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     height, width, layers = frames[0].shape\n#     video = cv2.VideoWriter(video_file, cv2.VideoWriter_fourcc(*'mp4v'), 24, (width, height))\n    \n#     for frame in frames:\n#         video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n    \n#     video.release()\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data_start_time = time.time()\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n#         logging.info(f\"Data loading and preprocessing took {time.time() - data_start_time:.2f} seconds\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_start_time = time.time()\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n#         logging.info(f\"EDA took {time.time() - eda_start_time:.2f} seconds\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         prompt_start_time = time.time()\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n#         logging.info(f\"Prompt analysis took {time.time() - prompt_start_time:.2f} seconds\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         video_start_time = time.time()\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n#         logging.info(f\"Video creation took {time.time() - video_start_time:.2f} seconds\")\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:43:34.705374Z","iopub.execute_input":"2025-01-03T12:43:34.705590Z","iopub.status.idle":"2025-01-03T12:43:34.720035Z","shell.execute_reply.started":"2025-01-03T12:43:34.705572Z","shell.execute_reply":"2025-01-03T12:43:34.719342Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# import logging\n# import os\n# import pandas as pd\n# import time\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import numpy as np\n# import io\n# from PIL import Image\n# from matplotlib.animation import FuncAnimation\n\n# def generate_animated_bar_chart(data):\n#     frames = []\n#     fig, ax = plt.subplots(figsize=(10, 6))\n#     categories = data['category'].unique()\n#     bars = ax.bar(categories, np.zeros(len(categories)))\n#     ax.set_ylim(0, data['value'].max())\n#     ax.set_title('Moving Bar Chart')\n#     ax.set_xlabel('Category')\n#     ax.set_ylabel('Value')\n\n#     def update_bar(frame):\n#         for bar, category in zip(bars, categories):\n#             bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n#         return bars\n\n#     ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n#     for i in range(len(data)):\n#         update_bar(i)\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#     plt.close(fig)\n#     return frames\n\n# def generate_animated_correlation_matrix(data):\n#     frames = []\n#     corr_matrix = data.corr()\n#     fig, ax = plt.subplots(figsize=(10, 6))\n#     sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#     ax.set_title('Correlation Matrix')\n#     buf = io.BytesIO()\n#     fig.savefig(buf, format='png')\n#     buf.seek(0)\n#     img = Image.open(buf)\n#     frames.append(np.array(img))\n#     plt.close(fig)\n#     return frames\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate animated bar chart frames\n#     if 'category' in data.columns and 'value' in data.columns:\n#         frames.extend(generate_animated_bar_chart(data))\n    \n#     # Generate animated correlation matrix frames\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         frames.extend(generate_animated_correlation_matrix(data))\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"module_generation_seaborn.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n    \n#     video = concatenate_videoclips(video_clips, method=\"compose\")\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:52:13.334745Z","iopub.execute_input":"2025-01-04T07:52:13.335051Z","iopub.status.idle":"2025-01-04T07:52:13.340672Z","shell.execute_reply.started":"2025-01-04T07:52:13.335028Z","shell.execute_reply":"2025-01-04T07:52:13.339766Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n# import numpy as np\n# import io\n# import pandas as pd\n# import time\n\n# def generate_default_frames(data):\n#     logging.info(\"Generating default frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             for col in numeric_columns:\n#                 ax.plot(data[date_column], data[col], label=col)\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n#             buf = io.BytesIO()\n#             fig.savefig(buf, format='png')\n#             buf.seek(0)\n#             img = Image.open(buf)\n#             frames.append(img)\n#             plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(img)\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} default frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"frames_animations.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = []\n#     for frame in frames:\n#         img_clip = ImageSequenceClip([np.array(frame)], fps=1)  # 1 frame per second\n#         img_clip = img_clip.set_duration(5)  # Each frame lasts 5 seconds\n#         video_clips.append(img_clip)\n    \n#     video = concatenate_videoclips(video_clips, method=\"compose\")\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_default_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=audio_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:52:16.653846Z","iopub.execute_input":"2025-01-04T07:52:16.654145Z","iopub.status.idle":"2025-01-04T07:52:16.659106Z","shell.execute_reply.started":"2025-01-04T07:52:16.654123Z","shell.execute_reply":"2025-01-04T07:52:16.658264Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# !pip install gtts\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n# import numpy as np\n# import io\n# import pandas as pd\n# import time\n# from matplotlib.animation import FuncAnimation\n# from gtts import gTTS\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             for i in range(len(data)):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(np.array(img))\n#             plt.close(fig)\n    \n#     # Generate a moving bar chart\n#     if 'category' in data.columns and 'value' in data.columns:\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         categories = data['category'].unique()\n#         bars = ax.bar(categories, np.zeros(len(categories)))\n#         ax.set_ylim(0, data['value'].max())\n#         ax.set_title('Moving Bar Chart')\n#         ax.set_xlabel('Category')\n#         ax.set_ylabel('Value')\n\n#         def update_bar(frame):\n#             for bar, category in zip(bars, categories):\n#                 bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n#             return bars\n\n#         ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n#         for i in range(len(data)):\n#             update_bar(i)\n#             buf = io.BytesIO()\n#             fig.savefig(buf, format='png')\n#             buf.seek(0)\n#             img = Image.open(buf)\n#             frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"composition_model.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = []\n#     for frame in frames:\n#         img_clip = ImageSequenceClip([frame], fps=1)  # 1 frame per second\n#         img_clip = img_clip.set_duration(2)  # Each frame lasts 2 seconds\n#         video_clips.append(img_clip)\n    \n#     video = concatenate_videoclips(video_clips, method=\"compose\")\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def generate_narration(text, output_file=\"narration.mp3\"):\n#     tts = gTTS(text=text, lang='en')\n#     tts.save(output_file)\n#     return output_file\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Generating narration...\")\n#         narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n#         narration_file = generate_narration(narration_text)\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=narration_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:52:20.866847Z","iopub.execute_input":"2025-01-04T07:52:20.867142Z","iopub.status.idle":"2025-01-04T07:52:20.872759Z","shell.execute_reply.started":"2025-01-04T07:52:20.867120Z","shell.execute_reply":"2025-01-04T07:52:20.871820Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n# import numpy as np\n# import io\n# import pandas as pd\n# import time\n# from matplotlib.animation import FuncAnimation\n# from gtts import gTTS\n\n# def generate_animated_gifs(data):\n#     logging.info(\"Generating animated GIFs from data\")\n#     gif_files = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             gif_file = \"time_series.gif\"\n#             ani.save(gif_file, writer='imagemagick')\n#             gif_files.append(gif_file)\n#             plt.close(fig)\n    \n#     # Generate a moving bar chart\n#     if 'category' in data.columns and 'value' in data.columns:\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         categories = data['category'].unique()\n#         bars = ax.bar(categories, np.zeros(len(categories)))\n#         ax.set_ylim(0, data['value'].max())\n#         ax.set_title('Moving Bar Chart')\n#         ax.set_xlabel('Category')\n#         ax.set_ylabel('Value')\n\n#         def update_bar(frame):\n#             for bar, category in zip(bars, categories):\n#                 bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n#             return bars\n\n#         ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n#         gif_file = \"moving_bar_chart.gif\"\n#         ani.save(gif_file, writer='imagemagick')\n#         gif_files.append(gif_file)\n#         plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         img.save(\"correlation_matrix.png\")\n#         gif_files.append(\"correlation_matrix.png\")\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         img.save(f\"distribution_{col}.png\")\n#         gif_files.append(f\"distribution_{col}.png\")\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(gif_files)} animated GIFs and images\")\n#     return gif_files\n\n# def create_video_from_gifs(gif_files, audio_file=None, video_file=\"gif_composition_video.mp4\"):\n#     if not gif_files:\n#         raise ValueError(\"No GIF files to create video from.\")\n    \n#     logging.info(\"Creating video from GIF files\")\n#     video_clips = []\n#     for gif_file in gif_files:\n#         if gif_file.endswith('.gif'):\n#             img_clip = ImageSequenceClip(gif_file, fps=1)  # 1 frame per second\n#         else:\n#             img_clip = ImageSequenceClip([gif_file], fps=1)  # 1 frame per second\n#         img_clip = img_clip.set_duration(5)  # Each frame lasts 5 seconds\n#         video_clips.append(img_clip)\n    \n#     video = concatenate_videoclips(video_clips, method=\"compose\")\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     gif_files = generate_animated_gifs(data)\n#     if not gif_files:\n#         raise ValueError(\"No GIF files generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         gif_files.insert(0, title_image)\n    \n#     create_video_from_gifs(gif_files, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def generate_narration(text, output_file=\"narration.mp3\"):\n#     tts = gTTS(text=text, lang='en')\n#     tts.save(output_file)\n#     return output_file\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Generating narration...\")\n#         narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n#         narration_file = generate_narration(narration_text)\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=narration_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n# prompt = \"Analyze the country and region data\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:52:22.586136Z","iopub.execute_input":"2025-01-04T07:52:22.586455Z","iopub.status.idle":"2025-01-04T07:52:22.591732Z","shell.execute_reply.started":"2025-01-04T07:52:22.586431Z","shell.execute_reply":"2025-01-04T07:52:22.590857Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import logging\n# import os\n# from PIL import Image\n# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n# import numpy as np\n# import io\n# import pandas as pd\n# import time\n# from matplotlib.animation import FuncAnimation\n# from gtts import gTTS\n\n# def generate_animated_frames(data):\n#     logging.info(\"Generating animated frames from data\")\n#     frames = []\n    \n#     # Generate a basic time series plot if a date column is present\n#     date_column = None\n#     for col in data.columns:\n#         if 'date' in col.lower() or 'time' in col.lower():\n#             date_column = col\n#             break\n    \n#     if date_column:\n#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#         if len(numeric_columns) > 0:\n#             fig, ax = plt.subplots(figsize=(10, 6))\n#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n#             ax.set_xlabel('Time')\n#             ax.set_ylabel('Values')\n#             ax.legend()\n\n#             def update(frame):\n#                 for line, col in zip(lines, numeric_columns):\n#                     line.set_data(data[date_column][:frame], data[col][:frame])\n#                 return lines\n\n#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n#             for i in range(len(data)):\n#                 update(i)\n#                 buf = io.BytesIO()\n#                 fig.savefig(buf, format='png')\n#                 buf.seek(0)\n#                 img = Image.open(buf)\n#                 frames.append(np.array(img))\n#             plt.close(fig)\n    \n#     # Generate an animated bar chart\n#     if 'category' in data.columns and 'value' in data.columns:\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         categories = data['category'].unique()\n#         bars = ax.bar(categories, np.zeros(len(categories)))\n#         ax.set_ylim(0, data['value'].max())\n#         ax.set_title('Animated Bar Chart')\n#         ax.set_xlabel('Category')\n#         ax.set_ylabel('Value')\n\n#         def update_bar(frame):\n#             for bar, category in zip(bars, categories):\n#                 bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n#             return bars\n\n#         ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n#         for i in range(len(data)):\n#             update_bar(i)\n#             buf = io.BytesIO()\n#             fig.savefig(buf, format='png')\n#             buf.seek(0)\n#             img = Image.open(buf)\n#             frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate an animated pie chart\n#     if 'category' in data.columns and 'value' in data.columns:\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         def update_pie(frame):\n#             ax.clear()\n#             ax.pie(data['value'][:frame], labels=data['category'][:frame], autopct='%1.1f%%')\n#             ax.set_title('Animated Pie Chart')\n\n#         ani = FuncAnimation(fig, update_pie, frames=len(data), blit=True)\n#         for i in range(len(data)):\n#             update_pie(i)\n#             buf = io.BytesIO()\n#             fig.savefig(buf, format='png')\n#             buf.seek(0)\n#             img = Image.open(buf)\n#             frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate a correlation matrix plot\n#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n#         corr_matrix = data.corr()\n#         fig, ax = plt.subplots(figsize=(10, 6))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n#         ax.set_title('Correlation Matrix')\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     # Generate distribution plots for numeric columns\n#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         fig, ax = plt.subplots(figsize=(8, 6))\n#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n#         ax.set_title(f\"Distribution of {col}\")\n#         buf = io.BytesIO()\n#         fig.savefig(buf, format='png')\n#         buf.seek(0)\n#         img = Image.open(buf)\n#         frames.append(np.array(img))\n#         plt.close(fig)\n    \n#     logging.info(f\"Generated {len(frames)} animated frames\")\n#     return frames\n\n# def create_video_from_frames(frames, audio_file=None, video_file=\"gif_new_composition.mp4\"):\n#     if not frames:\n#         raise ValueError(\"No frames to create video from.\")\n    \n#     logging.info(\"Creating video from frames\")\n#     video_clips = []\n#     for frame in frames:\n#         img_clip = ImageSequenceClip([frame], fps=1)  # 1 frame per second\n#         img_clip = img_clip.set_duration(2)  # Each frame lasts 2 seconds\n#         video_clips.append(img_clip)\n    \n#     video = concatenate_videoclips(video_clips, method=\"compose\")\n    \n#     if audio_file and os.path.isfile(audio_file):\n#         audio = AudioFileClip(audio_file)\n#         video = video.set_audio(audio)\n    \n#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n#     logging.info(f\"Video saved as {video_file}\")\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     frames = generate_animated_frames(data)\n#     if not frames:\n#         raise ValueError(\"No frames generated from data.\")\n    \n#     if os.path.exists(title_image):\n#         title_image_clip = Image.open(title_image)\n#         title_image_clip = title_image_clip.convert(\"RGBA\")\n#         title_image_clip = np.array(title_image_clip)\n#         frames.insert(0, title_image_clip)\n    \n#     create_video_from_frames(frames, audio_file)\n#     print(\"Video successfully generated!\")\n\n# def generate_narration(text, output_file=\"narration.mp3\"):\n#     tts = gTTS(text=text, lang='en')\n#     tts.save(output_file)\n#     return output_file\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Generating narration...\")\n#         narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n#         narration_file = generate_narration(narration_text)\n        \n#         logging.info(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=narration_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2017.csv'\n# prompt = \"compare the family and generaosity in an interactive video format\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:52:26.326017Z","iopub.execute_input":"2025-01-04T07:52:26.326312Z","iopub.status.idle":"2025-01-04T07:52:26.332005Z","shell.execute_reply.started":"2025-01-04T07:52:26.326290Z","shell.execute_reply":"2025-01-04T07:52:26.331202Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# import plotly.express as px\n# import pandas as pd\n# import logging\n# import os\n# import time\n# from moviepy.editor import ImageSequenceClip, concatenate_videoclips, AudioFileClip, VideoFileClip\n# from gtts import gTTS\n# from transformers import BartTokenizer, BartForConditionalGeneration\n# import spacy\n# import re\n# from sklearn.preprocessing import StandardScaler\n\n# # Setting up logging\n# logging.basicConfig(level=logging.INFO)\n\n# # Load spaCy model for NER\n# nlp = spacy.load(\"en_core_web_sm\")\n# import plotly.express as px\n# import pandas as pd\n# import logging\n# import os\n# import time\n# from moviepy.editor import ImageSequenceClip, concatenate_videoclips, AudioFileClip, VideoFileClip\n# from gtts import gTTS\n# from transformers import BartTokenizer, BartForConditionalGeneration\n# import spacy\n# import re\n# from sklearn.preprocessing import StandardScaler\n\n# # Setting up logging\n# logging.basicConfig(level=logging.INFO)\n\n# # Load spaCy model for NER\n# nlp = spacy.load(\"en_core_web_sm\")\n\n# def load_and_preprocess_data(file_path):\n#     try:\n#         logging.info(f\"Loading data from {file_path}\")\n#         print(f\"Loading data from {file_path}\")\n#         # Load data\n#         if file_path.endswith('.csv'):\n#             data = pd.read_csv(file_path)\n#         elif file_path.endswith('.xlsx'):\n#             data = pd.read_excel(file_path)\n#         elif file_path.endswith('.txt'):\n#             data = pd.read_csv(file_path, delimiter='\\t')\n#         else:\n#             raise ValueError(\"Unsupported file format.\")\n        \n#         logging.info(\"Data loaded successfully\")\n#         print(\"Data loaded successfully\")\n        \n#         # Detect and convert data types\n#         for col in data.columns:\n#             try:\n#                 data[col] = pd.to_numeric(data[col], errors='coerce')\n#             except ValueError:\n#                 pass\n        \n#         # Handle missing values\n#         data.fillna(data.mean(), inplace=True)\n        \n#         # Handle categorical data\n#         categorical_cols = data.select_dtypes(include=['object']).columns\n#         data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n        \n#         # Normalize numeric data\n#         numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n#         scaler = StandardScaler()\n#         data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n        \n#         # Add default columns if missing\n#         if 'date' not in data.columns:\n#             data['date'] = pd.date_range(start='1/1/2020', periods=len(data), freq='D')\n#         if 'value' not in data.columns:\n#             data['value'] = 1  # Default value\n#         if 'category' not in data.columns:\n#             data['category'] = 'default_category'\n        \n#         logging.info(\"Data preprocessing completed\")\n#         print(\"Data preprocessing completed\")\n#         return data\n#     except Exception as e:\n#         logging.error(f\"Error loading and preprocessing data: {e}\")\n#         print(f\"Error loading and preprocessing data: {e}\")\n#         raise\n\n# # The rest of the code remains the same\n\n# def infer_columns(data):\n#     try:\n#         column_mapping = {}\n#         possible_columns = {\n#             'category': ['category', 'type', 'class', 'label', 'country', 'region'],\n#             'value': ['value', 'amount', 'score', 'total', 'family', 'generosity'],\n#             'date': ['date', 'time', 'year', 'month', 'day'],\n#             'x': ['x', 'longitude', 'lat', 'latitude'],\n#             'y': ['y', 'latitude', 'long', 'longitude']\n#         }\n        \n#         logging.info(f\"Data columns: {data.columns.tolist()}\")\n#         print(f\"Data columns: {data.columns.tolist()}\")\n#         for key, patterns in possible_columns.items():\n#             for pattern in patterns:\n#                 potential_cols = [col for col in data.columns if re.search(pattern, col, re.IGNORECASE)]\n#                 if potential_cols:\n#                     column_mapping[key] = potential_cols[0]\n#                     break\n        \n#         # If any required column is missing, attempt to infer it\n#         if 'date' not in column_mapping:\n#             data['date'] = pd.date_range(start='1/1/2020', periods=len(data), freq='D')\n#             column_mapping['date'] = 'date'\n        \n#         if 'value' not in column_mapping:\n#             numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n#             if len(numeric_cols) > 0:\n#                 column_mapping['value'] = numeric_cols[0]\n#             else:\n#                 raise ValueError(\"Cannot infer 'value' column.\")\n        \n#         if 'category' not in column_mapping:\n#             categorical_cols = data.select_dtypes(include=['object']).columns\n#             if len(categorical_cols) > 0:\n#                 column_mapping['category'] = categorical_cols[0]\n#             else:\n#                 non_numeric_cols = data.select_dtypes(exclude=['float64', 'int64']).columns\n#                 if len(non_numeric_cols) > 0:\n#                     column_mapping['category'] = non_numeric_cols[0]\n#                 else:\n#                     raise ValueError(\"Cannot infer 'category' column.\")\n        \n#         return column_mapping\n#     except Exception as e:\n#         logging.error(f\"Error inferring columns: {e}\")\n#         print(f\"Error inferring columns: {e}\")\n#         raise\n\n# def generate_frames(data, chart_type, column_mapping, output_dir=\"frames\"):\n#     try:\n#         if not os.path.exists(output_dir):\n#             os.makedirs(output_dir)\n        \n#         frames = []\n#         for date in data[column_mapping['date']].unique():\n#             filtered_data = data[data[column_mapping['date']] == date]\n#             if chart_type == 'bar':\n#                 fig = px.bar(filtered_data, x=column_mapping['category'], y=column_mapping['value'], title=f\"Bar Chart - {date}\")\n#             elif chart_type == 'pie':\n#                 fig = px.pie(filtered_data, values=column_mapping['value'], names=column_mapping['category'], title=f\"Pie Chart - {date}\")\n#             elif chart_type == 'scatter':\n#                 fig = px.scatter(filtered_data, x=column_mapping['x'], y=column_mapping['y'], size=column_mapping['value'], color=column_mapping['category'], title=f\"Scatter Plot - {date}\")\n#             else:\n#                 raise ValueError(\"Invalid chart type\")\n            \n#             frame_path = os.path.join(output_dir, f\"{chart_type}_{date}.png\")\n#             fig.write_image(frame_path)\n#             frames.append(frame_path)\n        \n#         return frames\n#     except Exception as e:\n#         logging.error(f\"Error generating frames: {e}\")\n#         print(f\"Error generating frames: {e}\")\n#         raise\n\n# def generate_video_from_frames(frames, output_file=\"animation.mp4\", fps=1):\n#     try:\n#         clip = ImageSequenceClip(frames, fps=fps)\n#         clip.write_videofile(output_file, codec=\"libx264\")\n#         return output_file\n#     except Exception as e:\n#         logging.error(f\"Error generating video from frames: {e}\")\n#         print(f\"Error generating video from frames: {e}\")\n#         raise\n\n# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n#     try:\n#         logging.info(\"Checking data columns for required visualizations\")\n#         print(\"Checking data columns for required visualizations\")\n#         column_mapping = infer_columns(data)\n#         logging.debug(f\"Column mapping: {column_mapping}\")\n#         print(f\"Column mapping: {column_mapping}\")\n#         video_files = generate_videos_if_needed(data, column_mapping)\n        \n#         if not video_files:\n#             logging.error(\"No video files generated from data. Check if the data has the required columns.\")\n#             print(\"No video files generated from data. Check if the data has the required columns.\")\n#             raise ValueError(\"No video files generated from data.\")\n        \n#         logging.info(\"Combining video files into a single video\")\n#         print(\"Combining video files into a single video\")\n#         video_clips = [VideoFileClip(video_file) for video_file in video_files]\n        \n#         if os.path.exists(title_image):\n#             title_clip = VideoFileClip(title_image).set_duration(5)\n#             video_clips.insert(0, title_clip)\n        \n#         final_video = concatenate_videoclips(video_clips, method=\"compose\")\n        \n#         if audio_file and os.path.isfile(audio_file):\n#             audio = AudioFileClip(audio_file)\n#             final_video = final_video.set_audio(audio)\n        \n#         final_video.write_videofile(\"attemot_video.mp4\", codec=\"libx264\", fps=24)\n#         logging.info(\"Final video saved as final_video.mp4\")\n#         print(\"Final video saved as final_video.mp4\")\n#     except Exception as e:\n#         logging.error(f\"Error generating infographic video: {e}\")\n# def generate_videos_if_needed(data, column_mapping):\n#         raise\n\n# def generate_videos_if_needed(data):\n#     try:\n#         video_files = []\n#         column_mapping = infer_columns(data)\n#         required_columns = {'category', 'value', 'date'}\n#         if not required_columns.issubset(column_mapping.keys()):\n#             logging.error(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n#             print(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n#             raise ValueError(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n\n#         if required_columns.issubset(column_mapping.keys()):\n#             logging.info(\"Data contains required columns for bar and pie charts\")\n#             print(\"Data contains required columns for bar and pie charts\")\n#             try:\n#                 bar_frames = generate_frames(data, 'bar', column_mapping)\n#                 video_files.append(generate_video_from_frames(bar_frames, \"animated_bar_chart.mp4\"))\n#             except Exception as e:\n#                 logging.error(f\"Failed to generate animated bar chart: {e}\")\n#                 print(f\"Failed to generate animated bar chart: {e}\")\n#             try:\n#                 pie_frames = generate_frames(data, 'pie', column_mapping)\n#                 video_files.append(generate_video_from_frames(pie_frames, \"animated_pie_chart.mp4\"))\n#             except Exception as e:\n#                 logging.error(f\"Failed to generate animated pie chart: {e}\")\n#                 print(f\"Failed to generate animated pie chart: {e}\")\n#         if {'x', 'y', 'value', 'date'}.issubset(column_mapping.keys()):\n#             logging.info(\"Data contains required columns for scatter plot\")\n#             print(\"Data contains required columns for scatter plot\")\n#             try:\n#                 scatter_frames = generate_frames(data, 'scatter', column_mapping)\n#                 video_files.append(generate_video_from_frames(scatter_frames, \"animated_scatter_plot.mp4\"))\n#             except Exception as e:\n#                 logging.error(f\"Failed to generate animated scatter plot: {e}\")\n#                 print(f\"Failed to generate animated scatter plot: {e}\")\n#         return video_files\n#     except Exception as e:\n#         logging.error(f\"Error generating videos if needed: {e}\")\n#         print(f\"Error generating videos if needed: {e}\")\n#         raise\n\n# def generate_narration(text, output_file=\"narration.mp3\"):\n#     try:\n#         tts = gTTS(text=text, lang='en')\n#         tts.save(output_file)\n#         return output_file\n#     except Exception as e:\n#         logging.error(f\"Error generating narration: {e}\")\n#         print(f\"Error generating narration: {e}\")\n#         raise\n\n# def perform_eda(data):\n#     try:\n#         eda_summary = {\n#             \"shape\": data.shape,\n#             \"columns\": data.columns.tolist(),\n#             \"dtypes\": data.dtypes.tolist(),\n#             \"null_counts\": data.isnull().sum().tolist(),\n#             \"describe\": data.describe().to_dict()\n#         }\n#         return eda_summary\n#     except Exception as e:\n#         logging.error(f\"Error performing EDA: {e}\")\n#         print(f\"Error performing EDA: {e}\")\n#         raise\n\n# def analyze_prompt_for_insights(prompt, model_name=\"facebook/bart-large\"):\n#     try:\n#         logging.info(\"Analyzing prompt for insights\")\n#         print(\"Analyzing prompt for insights\")\n#         tokenizer = BartTokenizer.from_pretrained(model_name)\n#         model = BartForConditionalGeneration.from_pretrained(model_name)\n        \n#         inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n#         input_ids = inputs.input_ids\n#         attention_mask = inputs.attention_mask\n        \n#         outputs = model.generate(\n#             input_ids,\n#             attention_mask=attention_mask,\n#             max_length=200,\n#             num_return_sequences=1,\n#             temperature=0.7,\n#             top_p=0.9,\n#             top_k=50,\n#             no_repeat_ngram_size=2,\n#             pad_token_id=tokenizer.eos_token_id\n#         )\n        \n#         generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n#         insights = extract_insights_from_text(generated_text)\n        \n#         insights_list = [key for key, value in insights.items() if value]\n#         if not insights_list:\n#             logging.warning(\"No insights could be extracted from the provided prompt. Using default insights.\")\n#             print(\"No insights could be extracted from the provided prompt. Using default insights.\")\n#             insights_list = [\"trend\", \"comparison\"]\n        \n#         logging.info(f\"Insights extracted: {insights_list}\")\n#         print(f\"Insights extracted: {insights_list}\")\n#         return insights_list\n#     except Exception as e:\n#         logging.error(f\"Error in analyzing prompt for insights: {e}\")\n#         print(f\"Error in analyzing prompt for insights: {e}\")\n#         return [\"trend\", \"comparison\"]\n\n# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n#     try:\n#         start_time = time.time()\n        \n#         logging.info(\"Loading and preprocessing data...\")\n#         print(\"Loading and preprocessing data...\")\n#         data = load_and_preprocess_data(file_path)\n#         logging.debug(f\"Loaded Data: {data.head()}\")\n#         print(f\"Loaded Data: {data.head()}\")\n        \n#         logging.info(\"Performing EDA...\")\n#         print(\"Performing EDA...\")\n#         eda_summary = perform_eda(data)\n#         logging.debug(f\"EDA Summary: {eda_summary}\")\n#         print(f\"EDA Summary: {eda_summary}\")\n        \n#         logging.info(\"Analyzing the user's prompt...\")\n#         print(\"Analyzing the user's prompt...\")\n#         insights = analyze_prompt_for_insights(prompt)\n#         logging.debug(f\"Extracted insights: {insights}\")\n#         print(f\"Extracted insights: {insights}\")\n        \n#         logging.info(\"Generating narration...\")\n#         print(\"Generating narration...\")\n#         narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n#         narration_file = generate_narration(narration_text)\n        \n#         logging.info(\"Creating the infographic video...\")\n#         print(\"Creating the infographic video...\")\n#         generate_infographic_video(data, insights, audio_file=narration_file)\n        \n#         end_time = time.time()\n#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n#         print(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n    \n#     except FileNotFoundError as fnf_error:\n#         logging.error(f\"File not found: {fnf_error}\")\n#         print(f\"File not found: {fnf_error}\")\n#         raise\n#     except pd.errors.ParserError as parser_error:\n#         logging.error(f\"Error parsing the file: {parser_error}\")\n#         print(f\"Error parsing the file: {parser_error}\")\n#         raise\n#     except TypeError as type_error:\n#         logging.error(f\"Type error: {type_error}\")\n#         print(f\"Type error: {type_error}\")\n#         raise\n#     except ValueError as value_error:\n#         logging.error(f\"Value error: {value_error}\")\n#         print(f\"Value error: {value_error}\")\n#         raise\n#     except Exception as e:\n#         logging.error(f\"An unexpected error occurred: {e}\")\n#         print(f\"An unexpected error occurred: {e}\")\n#         raise\n\n# # Example usage:\n# file_path = '/kaggle/input/model-dataset-new-1/2017.csv'\n# prompt = \"analyse the family and generaosity columns data in the video format\"\n# audio_file = \"/kaggle/working/\"\n# title_image = \"/kaggle/working/\"\n\n# if not os.path.exists(file_path):\n#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n# if not os.path.exists(audio_file):\n#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n# if not os.path.exists(title_image):\n#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n\n# try:\n#     data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\n# except ValueError as e:\n#     if \"Missing required columns\" in str(e):\n#         logging.info(\"Adding missing columns to the data\")\n#         print(\"Adding missing columns to the data\")\n#         data = load_and_preprocess_data(file_path)\n#         column_mapping = infer_columns(data)\n        \n#         if 'date' not in column_mapping:\n#             data['date'] = pd.date_range(start='1/1/2020', periods=len(data), freq='D')\n        \n#         if 'value' not in column_mapping:\n#             data['value'] = data.select_dtypes(include=['float64', 'int64']).iloc[:, 0]\n        \n#         if 'category' not in column_mapping:\n#             data['category'] = 'default_category'\n        \n#         data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\n#     else:\n#         raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T07:35:39.849734Z","iopub.status.idle":"2025-01-04T07:35:39.850025Z","shell.execute_reply":"2025-01-04T07:35:39.849916Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# will work tommorow","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}